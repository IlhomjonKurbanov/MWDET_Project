## Introduction

In this project, we focus on mind-wandering detection during watching lecture videos. Since lecture videos are one of the main conponent in MOOCs and mind-wandering may have negative effects on learning performance in video watching. Previous work shows some relations between learners' mind-wandering and their gaze movements. However, all of these studies are based on professional but expensive eye tracking device. It is not applicable for average MOOC learners. Therefore, we investigate to what extent we can detect learners' mind-wandering based on webcam-based eye tracking in our project.

In this page, we first introduce a Web application which is used to collect participants' gaze data and reports of mind-wandering during watching lecture videos. Then we release the data about mind-wandering reports and the raw gaze data collected by both [Tobii](https://www.tobii.com/) and [WebGazer.js](http://webgazer.cs.brown.edu/)[1]. After a brief introduction of the dataset, the experiment results and classifier parameters, which are not included in our papers due to the space limitation, are introduced concretely. In the last part, we introduce the scripts leveraged in our work for data processing and mind-wandering detection.

## Web Application for Experiments

During the experiments, participants are asked to watch two lecture videos (i.e. [solar energy](https://www.youtube.com/watch?v=SNmKom56HqE) and [nuclear energy](https://www.youtube.com/watch?v=BW4Q9YQ2gAQ)). Before each video, there is a webcam setup and a calibration for WebGazer.js. In the webcam setup, participants are asked to make sure their faces are fully detected before the calibataion. In the calibration, participants are asked to click 40 dots randomly appearing in the screen.
The calibration of Tobii is conducted before the participants start interacting with the Web application.

In our experiments, Tobii studio runs in the background while participants are interacting with this Web application. When participants are watching lecture videos, their gaze data is recorded by both Tobii and the Web application at the same time. Their reports of mind-wandering are recorded by the Web application.

If you are interested in this Web application, the detail information and setup can be found in [this repository](https://github.com/Yue-ZHAO/MWDET_WebApp).

## Dataset

You can download the dataset [here](https://www.dropbox.com/s/1gl7mov3q0pbqrk/Data_Publish.zip?dl=0)

There are three folders for the following 3 kinds of data in the dataset. In each folder, a file contains the data of a participant.
1. Tobii Data (.csv files)
  - Coordinates (X, Y), timestamps, and durations of fixations
  - Angles of saccades
  - Coordinates (X, Y) and timestamps of gaze point

2. WebGazer Data (.csv files)
  - Raw data: coordinates (X, Y) and timestamp of gaze point 
  - Prcossed data: coordinates (X, Y) and timestamp of gaze point; coordinates (X, Y), timestamps, and durations of fixations; angles of saccades

3. Event Data (.json files)
  - Participants' report about their mind-wandering
  - The bell rings
  - Video playing status

The timestamps leveraged in this experiments are based on [ISO 8601](https://en.wikipedia.org/wiki/ISO_8601) (e.g. 2017-04-26T14:38:29.235Z) with UTC+0 timezone.

The video information (i.e. video playing time and video length) can be found from the event data. The lengths of the videos about [solar energy](https://www.youtube.com/watch?v=SNmKom56HqE) and [nuclear energy](https://www.youtube.com/watch?v=BW4Q9YQ2gAQ) are about 468 seconds and about 400 seconds respectively.

## Detection Results for Mind-Wandering

In the following table, we first list classifiers with parameters leveraged in our experiments. All of them are based on modules in scikit-learn.

| Classifier | Parameters | module |
| ---------- | ---------- | ------ |
| L1-Logistic Regression | Default Setting with penalty='l1', tol=0.01 | [sklearn.linear_model.LogisticRegression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) |
| L2-Logistic Regression | Default Setting with penalty='l2', tol=0.01 | [sklearn.linear_model.LogisticRegression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) |
| SVM | Default Setting with tol=0.01 | [sklearn.svm.SVC](http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC) |
| Decision Tree | Default Setting | [sklearn.tree.DecisionTreeClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)|
| GaussianNB | Default Setting| [sklearn.naive_bayes.GaussianNB](http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html) |

Then we list all the results generated by each classifier in the following.

| Method | Precision | Recall | F1-measure |
| ------ | ---------:| ------:| ----------:|
| Baseline | 0.290 | 0.291 | 0.290 |

The experiment results with Tobii Data are following.

| Data | Classifier | Feature | SMOTE | Precision | Recall | F1-measure |
| ---- | ---------- | ------- | ----- | ---------:| ------:| ----------:|
| Tobii Data | L1-Logistic Regression | Global | No | 0.419 | 0.224 | 0.292 |
| Tobii Data | L1-Logistic Regression | Global | Yes | 0.350 | 0.483 | 0.406 |
| Tobii Data | L1-Logistic Regression | Local | No | 0.143 | 0.017 | 0.031 |
| Tobii Data | L1-Logistic Regression | Local | Yes | 0.250 | 0.397 | 0.307 |
| Tobii Data | L1-Logistic Regression | Global+Local | No | 0.370 | 0.172 | 0.235 |
| Tobii Data | L1-Logistic Regression | Global+Local| Yes | 0.319 | 0.379 | 0.346 |

| Data | Classifier | Feature | SMOTE | Precision | Recall | F1-measure |
| ---- | ---------- | ------- | ----- | ---------:| ------:| ----------:|
| Tobii Data | L2-Logistic Regression | Global | No | 0.300 | 0.155 | 0.205 |
| Tobii Data | L2-Logistic Regression | Global | Yes | 0.375 | 0.517 | 0.435 |
| Tobii Data | L2-Logistic Regression | Local | No | 0.000 | 0.000 | 0.000 |
| Tobii Data | L2-Logistic Regression | Local | Yes | 0.274 | 0.534 | 0.363 |
| Tobii Data | L2-Logistic Regression | Global+Local | No | 0.300 | 0.155 | 0.205 |
| Tobii Data | L2-Logistic Regression | Global+Local| Yes | 0.328 | 0.379 | 0.352 |

<!-- | Data | Classifier | Feature | SMOTE | Precision | Recall | F1-measure |
| ---- | ---------- | ------- | ----- | ---------:| ------:| ----------:|
| Tobii Data | SVM | Global | No | 0.000 | 0.000 | 0.000 |
| Tobii Data | SVM | Global | Yes | 0.000 | 0.000 | 0.000 |
| Tobii Data | SVM | Local | No | 0.000 | 0.000 | 0.000 |
| Tobii Data | SVM | Local | Yes | 0.000 | 0.000 | 0.000 |
| Tobii Data | SVM | Global+Local | No | 0.000 | 0.000 | 0.000 |
| Tobii Data | SVM | Global+Local | Yes | 0.000 | 0.000 | 0.000 | -->

| Data | Classifier | Feature | SMOTE | Precision | Recall | F1-measure |
| ---- | ---------- | ------- | ----- | ---------:| ------:| ----------:|
| Tobii Data | Decision Tree | Global | No | 0.218 | 0.207 | 0.212 |
| Tobii Data | Decision Tree | Global | Yes | 0.203 | 0.241 | 0.220 |
| Tobii Data | Decision Tree | Local | No | 0.355 | 0.379 | 0.367 |
| Tobii Data | Decision Tree | Local | Yes | 0.250 | 0.328 | 0.284 |
| Tobii Data | Decision Tree | Global+Local | No | 0.324 | 0.379 | 0.349 |
| Tobii Data | Decision Tree | Global+Local | Yes | 0.313 | 0.362 | 0.336 |

| Data | Classifier | Feature | SMOTE | Precision | Recall | F1-measure |
| ---- | ---------- | ------- | ----- | ---------:| ------:| ----------:|
| Tobii Data | GaussianNB | Global | No | 0.309 | 0.362 | 0.333 |
| Tobii Data | GaussianNB | Global | Yes | 0.288 | 0.362 | 0.321 |
| Tobii Data | GaussianNB | Local | No | 0.448 | 0.224 | 0.299 |
| Tobii Data | GaussianNB | Local | Yes | 0.299 | 0.500 | 0.374 |
| Tobii Data | GaussianNB | Global+Local | No | 0.294 | 0.345 | 0.317 |
| Tobii Data | GaussianNB | Global+Local | Yes | 0.311 | 0.397 | 0.348 |

The experiment results with WebGazer Data are following.

| Data | Classifier | Feature | SMOTE | Precision | Recall | F1-measure |
| ---- | ---------- | ------- | ----- | ---------:| ------:| ----------:|
| WebGazer Data | L1-Logistic Regression | Global | No | 0.077 | 0.017 | 0.028 |
| WebGazer Data | L1-Logistic Regression | Global | Yes | 0.291 | 0.431 | 0.347 |
| WebGazer Data | L1-Logistic Regression | Local | No | 0.000 | 0.000 | 0.000 |
| WebGazer Data | L1-Logistic Regression | Local | Yes | 0.307 | 0.603 | 0.407 |
| WebGazer Data | L1-Logistic Regression | Global+Local | No | 0.238 | 0.086 | 0.127 |
| WebGazer Data | L1-Logistic Regression | Global+Local| Yes | 0.330 | 0.500 | 0.397 |

| Data | Classifier | Feature | SMOTE | Precision | Recall | F1-measure |
| ---- | ---------- | ------- | ----- | ---------:| ------:| ----------:|
| WebGazer Data | L2-Logistic Regression | Global | No | 0.154 | 0.034 | 0.056 |
| WebGazer Data | L2-Logistic Regression | Global | Yes | 0.245 | 0.397 | 0.303 |
| WebGazer Data | L2-Logistic Regression | Local | No | 0.000 | 0.000 | 0.000 |
| WebGazer Data | L2-Logistic Regression | Local | Yes | 0.300 | 0.362 | 0.328 |
| WebGazer Data | L2-Logistic Regression | Global+Local | No | 0.111 | 0.017 | 0.030 |
| WebGazer Data | L2-Logistic Regression | Global+Local| Yes | 0.305 | 0.500 | 0.379 |

<!-- | Data | Classifier | Feature | SMOTE | Precision | Recall | F1-measure |
| ---- | ---------- | ------- | ----- | ---------:| ------:| ----------:|
| WebGazer Data | SVM | Global | No | 0.000 | 0.000 | 0.000 |
| WebGazer Data | SVM | Global | Yes | 0.000 | 0.000 | 0.000 |
| WebGazer Data | SVM | Local | No | 0.000 | 0.000 | 0.000 |
| WebGazer Data | SVM | Local | Yes | 0.000 | 0.000 | 0.000 |
| WebGazer Data | SVM | Global+Local | No | 0.000 | 0.000 | 0.000 |
| WebGazer Data | SVM | Global+Local | Yes | 0.000 | 0.000 | 0.000 | -->

| Data | Classifier | Feature | SMOTE | Precision | Recall | F1-measure |
| ---- | ---------- | ------- | ----- | ---------:| ------:| ----------:|
| WebGazer Data | Decision Tree | Global | No | 0.232 | 0.276 | 0.252 |
| WebGazer Data | Decision Tree | Global | Yes | 0.231 | 0.310 | 0.265 |
| WebGazer Data | Decision Tree | Local | No | 0.324 | 0.397 | 0.357 |
| WebGazer Data | Decision Tree | Local | Yes | 0.292 | 0.448 | 0.354 |
| WebGazer Data | Decision Tree | Global+Local | No | 0.290 | 0.345 | 0.315 |
| WebGazer Data | Decision Tree | Global+Local | Yes | 0.282 | 0.345 | 0.310 |

| Data | Classifier | Feature | SMOTE | Precision | Recall | F1-measure |
| ---- | ---------- | ------- | ----- | ---------:| ------:| ----------:|
| WebGazer Data | GaussianNB | Global | No | 0.339 | 0.690 | 0.455 |
| WebGazer Data | GaussianNB | Global | Yes | 0.345 | 0.707 | 0.463 |
| WebGazer Data | GaussianNB | Local | No | 0.342 | 0.690 | 0.457 |
| WebGazer Data | GaussianNB | Local | Yes | 0.346 | 0.776 | 0.479 |
| WebGazer Data | GaussianNB | Global+Local | No | 0.352 | 0.776 | 0.484 |
| WebGazer Data | GaussianNB | Global+Local | Yes | 0.362 | 0.724 | 0.483 |

## Scripts

For the data processing and mind-wandering prediction, we have [3 main scripts](https://github.com/Yue-ZHAO/MWDET_Project/tree/master/Scripts) which are written as Jupyter notebooks.

1. Scripts 01 (in Python) for feature extraction and mind-wandering prediction based on Tobii data.
2. Scripts 02 (in R) for saccade detection based on WebGazer data (detection algorithm is based on [2])
3. Scripts 03 (in Python) for feature extraction and mind-wandering prediction based on WebGazer data preprocessed in 2.

Due to the randomazation of the techniques SMOTE [3], which is leveraged in our scripts for unbalanced data, the prediction results might be slightly different in each runs.

## Reference
[1] Papoutsaki, Alexandra, et al. "WebGazer: scalable webcam eye tracking using user interactions." IJCAI, 2016.

[2] Engbert, Ralf, and Reinhold Kliegl. "Microsaccades uncover the orientation of covert attention." Vision research 43.9 (2003): 1035-1045.

[3] Chawla, Nitesh V., et al. "SMOTE: synthetic minority over-sampling technique." Journal of artificial intelligence research 16 (2002): 321-357.
