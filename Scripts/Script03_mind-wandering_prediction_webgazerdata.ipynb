{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this document, we first extract learners' mind-wandering from the json data. Then we map the data on the timeline. We process the mind-wandering data generated by reporting and questions seperately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Reading\n",
    "In this step, we read gaze data of Tobii from a tsv file and mind-wandering reports from a json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "\n",
    "folderpath_webgazerdata_rprocessed = \"../Data_Publish/Data_WebGazer/Data_ProcessedByScript02\"\n",
    "folderpath_webgazerdata = \"../Data_Publish/Data_Event\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Reading Mind-Wandering Data\n",
    "We only read some important data columns from the json file.\n",
    "\n",
    "1. Rating\n",
    "2. Bell Rings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../Data_Publish/Data_Event/Anon01.json', '../Data_Publish/Data_Event/Anon02.json', '../Data_Publish/Data_Event/Anon03.json', '../Data_Publish/Data_Event/Anon04.json', '../Data_Publish/Data_Event/Anon05.json', '../Data_Publish/Data_Event/Anon06.json', '../Data_Publish/Data_Event/Anon07.json', '../Data_Publish/Data_Event/Anon08.json', '../Data_Publish/Data_Event/Anon09.json', '../Data_Publish/Data_Event/Anon10.json', '../Data_Publish/Data_Event/Anon11.json', '../Data_Publish/Data_Event/Anon12.json', '../Data_Publish/Data_Event/Anon13.json']\n",
      "['Anon01', 'Anon02', 'Anon03', 'Anon04', 'Anon05', 'Anon06', 'Anon07', 'Anon08', 'Anon09', 'Anon10', 'Anon11', 'Anon12', 'Anon13']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "list_filepath_report = []\n",
    "list_id_report = []\n",
    "for file in os.listdir(folderpath_webgazerdata):\n",
    "    if file.endswith(\".json\"):\n",
    "        list_filepath_report.append(os.path.join(folderpath_webgazerdata, file))\n",
    "        list_id_report.append(file[0:-5])\n",
    "        \n",
    "print list_filepath_report\n",
    "print list_id_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Format \n",
    "id, starttime_iso, endtime_iso, starttime_video, endtime_video, video_length, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anon01\n",
      "[]\n",
      "Anon02\n",
      "[{'exit': u'2017-04-12T11:28:33.178Z', 'enter': u'2017-04-12T11:20:41.610Z'}, {'exit': u'2017-04-12T11:40:20.780Z', 'enter': u'2017-04-12T11:33:36.025Z'}]\n",
      "Anon03\n",
      "[]\n",
      "Anon04\n",
      "[{'exit': u'2017-04-06T11:53:39.676Z', 'enter': u'2017-04-06T11:45:46.491Z'}, {'exit': u'2017-04-06T12:05:42.023Z', 'enter': u'2017-04-06T11:58:57.059Z'}]\n",
      "Anon05\n",
      "[]\n",
      "Anon06\n",
      "[]\n",
      "Anon07\n",
      "[{'exit': u'2017-04-13T12:45:32.365Z', 'enter': u'2017-04-13T12:38:52.824Z'}, {'exit': u'2017-04-13T12:59:46.088Z', 'enter': u'2017-04-13T12:51:58.970Z'}]\n",
      "Anon08\n",
      "[]\n",
      "Anon09\n",
      "[]\n",
      "Anon10\n",
      "[]\n",
      "Anon11\n",
      "[]\n",
      "Anon12\n",
      "[{'exit': u'2017-04-12T15:37:00.416Z', 'enter': u'2017-04-12T15:30:23.180Z'}, {'exit': u'2017-04-12T15:48:18.222Z', 'enter': u'2017-04-12T15:40:29.354Z'}]\n",
      "Anon13\n",
      "[{'exit': u'2017-04-12T14:32:31.031Z', 'enter': u'2017-04-12T14:24:43.184Z'}, {'exit': u'2017-04-12T14:43:27.772Z', 'enter': u'2017-04-12T14:36:46.908Z'}]\n",
      "                endtime_iso       endtime_video  fullscreen      id  label  \\\n",
      "0  2017-04-12T09:28:47.772Z           38.540809         0.0  Anon01    0.0   \n",
      "1  2017-04-12T09:29:34.224Z    85.0593229256134         0.0  Anon01    0.0   \n",
      "2  2017-04-12T09:30:35.276Z  146.13896398283387         0.0  Anon01    0.0   \n",
      "3  2017-04-12T09:31:36.727Z          206.331911         0.0  Anon01    0.0   \n",
      "4  2017-04-12T09:32:33.103Z  263.93422694659426         0.0  Anon01    0.0   \n",
      "5  2017-04-12T09:33:34.025Z           323.57275         0.0  Anon01    1.0   \n",
      "6  2017-04-12T09:34:11.537Z          362.089951         0.0  Anon01    0.0   \n",
      "7  2017-04-12T09:40:29.560Z           41.821216         0.0  Anon01    0.0   \n",
      "8  2017-04-12T09:41:28.162Z  100.62706982833862         0.0  Anon01    0.0   \n",
      "9  2017-04-12T09:42:27.429Z  159.88924984931947         0.0  Anon01    0.0   \n",
      "\n",
      "              starttime_iso starttime_video video_id       video_length  \\\n",
      "0  2017-04-12T09:28:17.772Z        8.540809  Nuclear            400.921   \n",
      "1  2017-04-12T09:29:04.224Z   55.0593229256  Nuclear            400.921   \n",
      "2  2017-04-12T09:30:05.276Z   116.138963983  Nuclear            400.921   \n",
      "3  2017-04-12T09:31:06.727Z      176.331911  Nuclear            400.921   \n",
      "4  2017-04-12T09:32:03.103Z   233.934226947  Nuclear            400.921   \n",
      "5  2017-04-12T09:33:04.025Z       293.57275  Nuclear            400.921   \n",
      "6  2017-04-12T09:33:41.537Z      332.089951  Nuclear            400.921   \n",
      "7  2017-04-12T09:39:59.560Z       11.821216    Solar  468.0214058956916   \n",
      "8  2017-04-12T09:40:58.162Z   70.6270698283    Solar  468.0214058956916   \n",
      "9  2017-04-12T09:41:57.429Z   129.889249849    Solar  468.0214058956916   \n",
      "\n",
      "   video_order  \n",
      "0          1.0  \n",
      "1          1.0  \n",
      "2          1.0  \n",
      "3          1.0  \n",
      "4          1.0  \n",
      "5          1.0  \n",
      "6          1.0  \n",
      "7          2.0  \n",
      "8          2.0  \n",
      "9          2.0  \n",
      "(200, 10)\n",
      "(58, 10)\n",
      "(142, 10)\n",
      "[ 1.  1.  1.  1.  1.  1.  1.  2.  2.  2.  2.  2.  2.  2.  2.  2.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  2.  2.  2.  2.  2.  2.  2.  2.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  2.  2.  2.  2.  2.  2.  2.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  2.  2.  2.  2.  2.  2.  2.  1.  1.  1.  1.  1.  1.  1.  2.  2.\n",
      "  2.  2.  2.  2.  2.  2.  1.  1.  1.  1.  1.  1.  1.  2.  2.  2.  2.  2.\n",
      "  2.  2.  2.  1.  1.  1.  1.  1.  1.  2.  2.  2.  2.  2.  2.  2.  2.  1.\n",
      "  1.  1.  1.  1.  1.  1.  2.  2.  2.  2.  2.  2.  2.  2.  1.  1.  1.  1.\n",
      "  1.  1.  1.  2.  2.  2.  2.  2.  2.  2.  2.  2.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  2.  2.  2.  2.  2.  2.  2.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  2.  2.  2.  2.  2.  2.  2.  1.  1.  1.  1.  1.  1.  1.  2.  2.  2.\n",
      "  2.  2.  2.  2.  2.  1.  1.  1.  1.  1.  1.  1.  1.  2.  2.  2.  2.  2.\n",
      "  2.  2.]\n",
      "['Nuclear' 'Nuclear' 'Nuclear' 'Nuclear' 'Nuclear' 'Nuclear' 'Nuclear'\n",
      " 'Solar' 'Solar' 'Solar' 'Solar' 'Solar' 'Solar' 'Solar' 'Solar' 'Solar'\n",
      " 'Solar' 'Solar' 'Solar' 'Solar' 'Solar' 'Solar' 'Solar' 'Solar' 'Solar'\n",
      " 'Nuclear' 'Nuclear' 'Nuclear' 'Nuclear' 'Nuclear' 'Nuclear' 'Nuclear'\n",
      " 'Nuclear' 'Solar' 'Solar' 'Solar' 'Solar' 'Solar' 'Solar' 'Solar' 'Solar'\n",
      " 'Nuclear' 'Nuclear' 'Nuclear' 'Nuclear' 'Nuclear' 'Nuclear' 'Nuclear'\n",
      " 'Solar' 'Solar' 'Solar' 'Solar' 'Solar' 'Solar' 'Solar' 'Solar' 'Nuclear'\n",
      " 'Nuclear' 'Nuclear' 'Nuclear' 'Nuclear' 'Nuclear' 'Nuclear' 'Nuclear'\n",
      " 'Nuclear' 'Nuclear' 'Nuclear' 'Nuclear' 'Nuclear' 'Nuclear' 'Solar'\n",
      " 'Solar' 'Solar' 'Solar' 'Solar' 'Solar' 'Solar' 'Solar' 'Nuclear'\n",
      " 'Nuclear' 'Nuclear' 'Nuclear' 'Nuclear' 'Nuclear' 'Nuclear' 'Solar'\n",
      " 'Solar' 'Solar' 'Solar' 'Solar' 'Solar' 'Solar' 'Solar' 'Nuclear'\n",
      " 'Nuclear' 'Nuclear' 'Nuclear' 'Nuclear' 'Nuclear' 'Solar' 'Solar' 'Solar'\n",
      " 'Solar' 'Solar' 'Solar' 'Solar' 'Solar' 'Nuclear' 'Nuclear' 'Nuclear'\n",
      " 'Nuclear' 'Nuclear' 'Nuclear' 'Nuclear' 'Solar' 'Solar' 'Solar' 'Solar'\n",
      " 'Solar' 'Solar' 'Solar' 'Solar' 'Nuclear' 'Nuclear' 'Nuclear' 'Nuclear'\n",
      " 'Nuclear' 'Nuclear' 'Nuclear' 'Solar' 'Solar' 'Solar' 'Solar' 'Solar'\n",
      " 'Solar' 'Solar' 'Solar' 'Solar' 'Solar' 'Solar' 'Solar' 'Solar' 'Solar'\n",
      " 'Solar' 'Solar' 'Solar' 'Solar' 'Nuclear' 'Nuclear' 'Nuclear' 'Nuclear'\n",
      " 'Nuclear' 'Nuclear' 'Nuclear' 'Solar' 'Solar' 'Solar' 'Solar' 'Solar'\n",
      " 'Solar' 'Solar' 'Solar' 'Solar' 'Nuclear' 'Nuclear' 'Nuclear' 'Nuclear'\n",
      " 'Nuclear' 'Nuclear' 'Nuclear' 'Nuclear' 'Nuclear' 'Nuclear' 'Nuclear'\n",
      " 'Nuclear' 'Nuclear' 'Nuclear' 'Solar' 'Solar' 'Solar' 'Solar' 'Solar'\n",
      " 'Solar' 'Solar' 'Solar' 'Solar' 'Solar' 'Solar' 'Solar' 'Solar' 'Solar'\n",
      " 'Solar' 'Solar' 'Nuclear' 'Nuclear' 'Nuclear' 'Nuclear' 'Nuclear'\n",
      " 'Nuclear' 'Nuclear']\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "df_reports = pd.DataFrame()\n",
    "\n",
    "for i in range(0, len(list_id_report)):\n",
    "    # id\n",
    "    id_str = list_id_report[i]\n",
    "    print id_str\n",
    "    # starttime_iso, endtime_iso, starttime_video, endtime_video, video_length, label\n",
    "    with open(list_filepath_report[i]) as file_json_data:\n",
    "        json_data = json.load(file_json_data)\n",
    "        # print(json_data['activity'])\n",
    "        \n",
    "        # TODO: full screen playing info\n",
    "        fullscreen_list = []\n",
    "        fullscreen_temp = {'enter': '', 'exit': ''}\n",
    "        for videostatus in json_data['user']['videostatus']:\n",
    "            if videostatus['status'] == 'Fullscreen_enter':\n",
    "                fullscreen_temp = {'enter': '', 'exit': ''}\n",
    "                fullscreen_temp['enter'] = videostatus['time']\n",
    "            elif videostatus['status'] == 'Fullscreen_exit':\n",
    "                if (fullscreen_temp['enter'] != ''):\n",
    "                    fullscreen_temp['exit'] = videostatus['time']\n",
    "                    fullscreen_list.append(fullscreen_temp)\n",
    "                    fullscreen_temp = {'enter': '', 'exit': ''}\n",
    "            elif videostatus['status'] == 'ENDED':\n",
    "                if (fullscreen_temp['enter'] != ''):\n",
    "                    fullscreen_temp['exit'] = videostatus['time']\n",
    "                    fullscreen_list.append(fullscreen_temp)\n",
    "                    fullscreen_temp = {'enter': '', 'exit': ''}           \n",
    "        \n",
    "        print fullscreen_list\n",
    "        \n",
    "        pre_video_id = \"\"\n",
    "        video_order = 1\n",
    "        \n",
    "        for bell in json_data['user']['ratingbells']:\n",
    "            ## End time is the time when bell rings\n",
    "            endtime_iso = bell['time']\n",
    "            # print endtime_iso\n",
    "            endtime_iso_datetime = datetime.datetime.strptime(endtime_iso, \"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "            ## Start time is 30 sec before the end time\n",
    "            starttime_iso_datetime = endtime_iso_datetime - datetime.timedelta(seconds=30)\n",
    "            (dt, micro) = starttime_iso_datetime.strftime('%Y-%m-%dT%H:%M:%S.%f').split('.')\n",
    "            starttime_iso = \"%s.%03dZ\" % (dt, int(micro) / 1000)\n",
    "            # print starttime_iso\n",
    "            \n",
    "            endtime_video = bell['videoTime']\n",
    "            # print endtime_video\n",
    "            ## There is no stop in last 30 sec before the bell rings. \n",
    "            ## Since each time the video playing starts, they will ring the bell after 30 sec.\n",
    "            starttime_video = str(float(endtime_video) - 30)\n",
    "            # print starttime_video\n",
    "            \n",
    "            video_length = bell['videoDuration']\n",
    "            # print video_length\n",
    "\n",
    "            video_id = \"\"           \n",
    "            if float(video_length) < 420:\n",
    "                video_id = \"Nuclear\"  \n",
    "            else:\n",
    "                video_id = \"Solar\"\n",
    "            \n",
    "            if pre_video_id == \"\":\n",
    "                video_order = 1\n",
    "                pre_video_id = video_id\n",
    "            elif video_id != pre_video_id:\n",
    "                video_order = video_order + 1\n",
    "                pre_video_id = video_id\n",
    "            \n",
    "            label = 0\n",
    "            for rating in json_data['user']['ratings']:\n",
    "                ratingtime_iso = rating['time']\n",
    "                # print ratingtime_iso\n",
    "                ratingtime_iso_datetime = datetime.datetime.strptime(ratingtime_iso, \"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "                if ratingtime_iso_datetime > endtime_iso_datetime and ratingtime_iso_datetime < endtime_iso_datetime + datetime.timedelta(seconds=10):\n",
    "                    label = 1\n",
    "                    break\n",
    "            # print label          \n",
    "            \n",
    "            fullscreen_flag = 0\n",
    "            for fullscreen_play in fullscreen_list:\n",
    "                if (starttime_iso > fullscreen_play['enter']) and (endtime_iso < fullscreen_play['exit']):\n",
    "                    fullscreen_flag = 1\n",
    "                    break\n",
    "            \n",
    "            ## Add data into dataframe\n",
    "            df_reports = df_reports.append({'id': id_str,\n",
    "                                            'video_id': video_id,\n",
    "                                            'video_order': video_order,\n",
    "                                            'starttime_iso': starttime_iso, \n",
    "                                            'endtime_iso': endtime_iso,\n",
    "                                            'starttime_video': starttime_video,\n",
    "                                            'endtime_video': endtime_video,\n",
    "                                            'video_length': video_length,\n",
    "                                            'label': label,\n",
    "                                            'fullscreen': fullscreen_flag\n",
    "                                           }, \n",
    "                                           ignore_index=True)\n",
    "print df_reports.head(10)\n",
    "print df_reports.shape\n",
    "print df_reports[df_reports['label'] == 1].shape\n",
    "print df_reports[df_reports['label'] == 0].shape\n",
    "print df_reports.video_order.values\n",
    "print df_reports.video_id.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Reading WebGazer Gaze Data\n",
    "We only read some important data columns from the tsv file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anon01\n",
      "../Data_Publish/Data_WebGazer/Data_ProcessedByScript02/Anon01.csv\n",
      "2017-04-12T09:28:17.772Z\n",
      "2017-04-12T09:28:47.772Z\n",
      "47\n",
      "74\n",
      "73\n",
      "73\n",
      "74\n",
      "0\n",
      "2\n",
      "2\n",
      "70\n",
      "2017-04-12T09:29:04.224Z\n",
      "2017-04-12T09:29:34.224Z\n",
      "50\n",
      "76\n",
      "75\n",
      "75\n",
      "76\n",
      "0\n",
      "0\n",
      "2\n",
      "74\n",
      "2017-04-12T09:30:05.276Z\n",
      "2017-04-12T09:30:35.276Z\n",
      "51\n",
      "78\n",
      "77\n",
      "77\n",
      "78\n",
      "0\n",
      "1\n",
      "3\n",
      "74\n",
      "2017-04-12T09:31:06.727Z\n",
      "2017-04-12T09:31:36.727Z\n",
      "46\n",
      "69\n",
      "68\n",
      "68\n",
      "69\n",
      "1\n",
      "2\n",
      "2\n",
      "64\n",
      "2017-04-12T09:32:03.103Z\n",
      "2017-04-12T09:32:33.103Z\n",
      "49\n",
      "76\n",
      "75\n",
      "75\n",
      "76\n",
      "0\n",
      "0\n",
      "3\n",
      "73\n",
      "2017-04-12T09:33:04.025Z\n",
      "2017-04-12T09:33:34.025Z\n",
      "51\n",
      "65\n",
      "64\n",
      "64\n",
      "65\n",
      "0\n",
      "0\n",
      "0\n",
      "65\n",
      "2017-04-12T09:33:41.537Z\n",
      "2017-04-12T09:34:11.537Z\n",
      "38\n",
      "64\n",
      "63\n",
      "63\n",
      "64\n",
      "0\n",
      "1\n",
      "2\n",
      "61\n",
      "2017-04-12T09:39:59.560Z\n",
      "2017-04-12T09:40:29.560Z\n",
      "38\n",
      "67\n",
      "66\n",
      "66\n",
      "67\n",
      "1\n",
      "0\n",
      "2\n",
      "64\n",
      "2017-04-12T09:40:58.162Z\n",
      "2017-04-12T09:41:28.162Z\n",
      "51\n",
      "88\n",
      "87\n",
      "87\n",
      "88\n",
      "0\n",
      "0\n",
      "0\n",
      "88\n",
      "2017-04-12T09:41:57.429Z\n",
      "2017-04-12T09:42:27.429Z\n",
      "55\n",
      "82\n",
      "81\n",
      "81\n",
      "82\n",
      "0\n",
      "0\n",
      "2\n",
      "80\n",
      "2017-04-12T09:42:59.020Z\n",
      "2017-04-12T09:43:29.020Z\n",
      "78\n",
      "128\n",
      "127\n",
      "127\n",
      "128\n",
      "0\n",
      "1\n",
      "0\n",
      "127\n",
      "2017-04-12T09:43:50.584Z\n",
      "2017-04-12T09:44:20.584Z\n",
      "73\n",
      "138\n",
      "137\n",
      "137\n",
      "138\n",
      "1\n",
      "8\n",
      "7\n",
      "122\n",
      "2017-04-12T09:44:34.770Z\n",
      "2017-04-12T09:45:04.770Z\n",
      "73\n",
      "134\n",
      "133\n",
      "133\n",
      "134\n",
      "0\n",
      "1\n",
      "4\n",
      "129\n",
      "2017-04-12T09:45:16.779Z\n",
      "2017-04-12T09:45:46.779Z\n",
      "65\n",
      "124\n",
      "123\n",
      "123\n",
      "124\n",
      "0\n",
      "0\n",
      "1\n",
      "123\n",
      "2017-04-12T09:46:05.371Z\n",
      "2017-04-12T09:46:35.371Z\n",
      "72\n",
      "126\n",
      "125\n",
      "125\n",
      "126\n",
      "2\n",
      "3\n",
      "2\n",
      "119\n",
      "2017-04-12T09:46:38.563Z\n",
      "2017-04-12T09:47:08.563Z\n",
      "85\n",
      "132\n",
      "131\n",
      "131\n",
      "132\n",
      "0\n",
      "0\n",
      "5\n",
      "127\n",
      "Anon02\n",
      "../Data_Publish/Data_WebGazer/Data_ProcessedByScript02/Anon02.csv\n",
      "2017-04-12T11:20:52.331Z\n",
      "2017-04-12T11:21:22.331Z\n",
      "50\n",
      "110\n",
      "109\n",
      "109\n",
      "110\n",
      "7\n",
      "7\n",
      "22\n",
      "74\n",
      "2017-04-12T11:21:45.426Z\n",
      "2017-04-12T11:22:15.426Z\n",
      "40\n",
      "104\n",
      "103\n",
      "103\n",
      "104\n",
      "2\n",
      "6\n",
      "58\n",
      "38\n",
      "2017-04-12T11:22:39.261Z\n",
      "2017-04-12T11:23:09.261Z\n",
      "40\n",
      "91\n",
      "90\n",
      "90\n",
      "91\n",
      "13\n",
      "2\n",
      "33\n",
      "43\n",
      "2017-04-12T11:23:27.088Z\n",
      "2017-04-12T11:23:57.088Z\n",
      "39\n",
      "106\n",
      "105\n",
      "105\n",
      "106\n",
      "5\n",
      "2\n",
      "45\n",
      "54\n",
      "2017-04-12T11:24:13.152Z\n",
      "2017-04-12T11:24:43.152Z\n",
      "51\n",
      "116\n",
      "115\n",
      "115\n",
      "116\n",
      "17\n",
      "0\n",
      "47\n",
      "52\n",
      "2017-04-12T11:25:16.437Z\n",
      "2017-04-12T11:25:46.437Z\n",
      "36\n",
      "79\n",
      "78\n",
      "78\n",
      "79\n",
      "8\n",
      "0\n",
      "30\n",
      "41\n",
      "2017-04-12T11:26:07.536Z\n",
      "2017-04-12T11:26:37.536Z\n",
      "44\n",
      "99\n",
      "98\n",
      "98\n",
      "99\n",
      "9\n",
      "1\n",
      "47\n",
      "42\n",
      "2017-04-12T11:26:39.169Z\n",
      "2017-04-12T11:27:09.169Z\n",
      "45\n",
      "98\n",
      "97\n",
      "97\n",
      "98\n",
      "1\n",
      "1\n",
      "58\n",
      "38\n",
      "2017-04-12T11:27:44.365Z\n",
      "2017-04-12T11:28:14.365Z\n",
      "44\n",
      "103\n",
      "102\n",
      "102\n",
      "103\n",
      "2\n",
      "0\n",
      "40\n",
      "61\n",
      "2017-04-12T11:33:48.453Z\n",
      "2017-04-12T11:34:18.453Z\n",
      "44\n",
      "144\n",
      "143\n",
      "143\n",
      "144\n",
      "11\n",
      "5\n",
      "27\n",
      "101\n",
      "2017-04-12T11:34:39.691Z\n",
      "2017-04-12T11:35:09.691Z\n",
      "52\n",
      "147\n",
      "146\n",
      "146\n",
      "147\n",
      "4\n",
      "1\n",
      "19\n",
      "123\n",
      "2017-04-12T11:35:34.277Z\n",
      "2017-04-12T11:36:04.277Z\n",
      "56\n",
      "137\n",
      "136\n",
      "136\n",
      "137\n",
      "10\n",
      "2\n",
      "20\n",
      "105\n",
      "2017-04-12T11:36:28.353Z\n",
      "2017-04-12T11:36:58.353Z\n",
      "44\n",
      "147\n",
      "146\n",
      "146\n",
      "147\n",
      "11\n",
      "4\n",
      "18\n",
      "114\n",
      "2017-04-12T11:37:02.694Z\n",
      "2017-04-12T11:37:32.694Z\n",
      "48\n",
      "145\n",
      "144\n",
      "144\n",
      "145\n",
      "5\n",
      "0\n",
      "22\n",
      "118\n",
      "2017-04-12T11:37:49.711Z\n",
      "2017-04-12T11:38:19.711Z\n",
      "65\n",
      "148\n",
      "147\n",
      "147\n",
      "148\n",
      "4\n",
      "7\n",
      "21\n",
      "116\n",
      "2017-04-12T11:38:35.091Z\n",
      "2017-04-12T11:39:05.091Z\n",
      "55\n",
      "147\n",
      "146\n",
      "146\n",
      "147\n",
      "8\n",
      "0\n",
      "24\n",
      "115\n",
      "2017-04-12T11:39:15.454Z\n",
      "2017-04-12T11:39:45.454Z\n",
      "52\n",
      "147\n",
      "146\n",
      "146\n",
      "147\n",
      "11\n",
      "2\n",
      "8\n",
      "126\n",
      "Anon03\n",
      "../Data_Publish/Data_WebGazer/Data_ProcessedByScript02/Anon03.csv\n",
      "2017-04-10T12:45:32.175Z\n",
      "2017-04-10T12:46:02.175Z\n",
      "37\n",
      "133\n",
      "132\n",
      "132\n",
      "133\n",
      "1\n",
      "9\n",
      "4\n",
      "119\n",
      "2017-04-10T12:46:37.669Z\n",
      "2017-04-10T12:47:07.669Z\n",
      "28\n",
      "100\n",
      "99\n",
      "99\n",
      "100\n",
      "1\n",
      "3\n",
      "1\n",
      "95\n",
      "2017-04-10T12:47:34.462Z\n",
      "2017-04-10T12:48:04.462Z\n",
      "30\n",
      "82\n",
      "81\n",
      "81\n",
      "82\n",
      "2\n",
      "4\n",
      "1\n",
      "75\n",
      "2017-04-10T12:48:16.879Z\n",
      "2017-04-10T12:48:46.879Z\n",
      "33\n",
      "82\n",
      "81\n",
      "81\n",
      "82\n",
      "0\n",
      "1\n",
      "0\n",
      "81\n",
      "2017-04-10T12:48:58.219Z\n",
      "2017-04-10T12:49:28.219Z\n",
      "37\n",
      "115\n",
      "114\n",
      "114\n",
      "115\n",
      "0\n",
      "0\n",
      "1\n",
      "114\n",
      "2017-04-10T12:50:06.403Z\n",
      "2017-04-10T12:50:36.403Z\n",
      "47\n",
      "127\n",
      "126\n",
      "126\n",
      "127\n",
      "0\n",
      "1\n",
      "2\n",
      "124\n",
      "2017-04-10T12:50:45.555Z\n",
      "2017-04-10T12:51:15.555Z\n",
      "40\n",
      "121\n",
      "120\n",
      "120\n",
      "121\n",
      "0\n",
      "1\n",
      "0\n",
      "120\n",
      "2017-04-10T12:51:53.243Z\n",
      "2017-04-10T12:52:23.243Z\n",
      "41\n",
      "110\n",
      "109\n",
      "109\n",
      "110\n",
      "1\n",
      "4\n",
      "1\n",
      "104\n",
      "2017-04-10T12:58:05.532Z\n",
      "2017-04-10T12:58:35.532Z\n",
      "74\n",
      "145\n",
      "144\n",
      "144\n",
      "145\n",
      "2\n",
      "11\n",
      "3\n",
      "129\n",
      "2017-04-10T12:58:57.443Z\n",
      "2017-04-10T12:59:27.443Z\n",
      "57\n",
      "136\n",
      "135\n",
      "135\n",
      "136\n",
      "0\n",
      "9\n",
      "12\n",
      "115\n",
      "2017-04-10T13:00:02.384Z\n",
      "2017-04-10T13:00:32.384Z\n",
      "60\n",
      "129\n",
      "128\n",
      "128\n",
      "129\n",
      "1\n",
      "7\n",
      "17\n",
      "104\n",
      "2017-04-10T13:00:43.130Z\n",
      "2017-04-10T13:01:13.130Z\n",
      "67\n",
      "130\n",
      "129\n",
      "129\n",
      "130\n",
      "1\n",
      "5\n",
      "10\n",
      "114\n",
      "2017-04-10T13:01:46.887Z\n",
      "2017-04-10T13:02:16.887Z\n",
      "47\n",
      "126\n",
      "125\n",
      "125\n",
      "126\n",
      "0\n",
      "2\n",
      "19\n",
      "105\n",
      "2017-04-10T13:02:28.154Z\n",
      "2017-04-10T13:02:58.154Z\n",
      "56\n",
      "128\n",
      "127\n",
      "127\n",
      "128\n",
      "0\n",
      "15\n",
      "8\n",
      "105\n",
      "2017-04-10T13:03:30.482Z\n",
      "2017-04-10T13:04:00.482Z\n",
      "58\n",
      "131\n",
      "130\n",
      "130\n",
      "131\n",
      "2\n",
      "12\n",
      "8\n",
      "109\n",
      "Anon04\n",
      "../Data_Publish/Data_WebGazer/Data_ProcessedByScript02/Anon04.csv\n",
      "2017-04-06T11:46:07.870Z\n",
      "2017-04-06T11:46:37.870Z\n",
      "103\n",
      "143\n",
      "142\n",
      "142\n",
      "143\n",
      "2\n",
      "0\n",
      "22\n",
      "119\n",
      "2017-04-06T11:47:13.287Z\n",
      "2017-04-06T11:47:43.287Z\n",
      "92\n",
      "128\n",
      "127\n",
      "127\n",
      "128\n",
      "2\n",
      "1\n",
      "4\n",
      "121\n",
      "2017-04-06T11:48:13.538Z\n",
      "2017-04-06T11:48:43.538Z\n",
      "93\n",
      "143\n",
      "142\n",
      "142\n",
      "143\n",
      "3\n",
      "1\n",
      "8\n",
      "131\n",
      "2017-04-06T11:48:54.685Z\n",
      "2017-04-06T11:49:24.685Z\n",
      "78\n",
      "140\n",
      "139\n",
      "139\n",
      "140\n",
      "5\n",
      "0\n",
      "19\n",
      "116\n",
      "2017-04-06T11:49:42.616Z\n",
      "2017-04-06T11:50:12.616Z\n",
      "89\n",
      "138\n",
      "137\n",
      "137\n",
      "138\n",
      "1\n",
      "0\n",
      "2\n",
      "135\n",
      "2017-04-06T11:50:38.245Z\n",
      "2017-04-06T11:51:08.245Z\n",
      "85\n",
      "128\n",
      "127\n",
      "127\n",
      "128\n",
      "0\n",
      "0\n",
      "3\n",
      "125\n",
      "2017-04-06T11:51:23.143Z\n",
      "2017-04-06T11:51:53.143Z\n",
      "92\n",
      "141\n",
      "140\n",
      "140\n",
      "141\n",
      "0\n",
      "1\n",
      "10\n",
      "130\n",
      "2017-04-06T11:52:33.099Z\n",
      "2017-04-06T11:53:03.099Z\n",
      "43\n",
      "69\n",
      "68\n",
      "68\n",
      "69\n",
      "2\n",
      "0\n",
      "2\n",
      "65\n",
      "2017-04-06T11:59:17.108Z\n",
      "2017-04-06T11:59:47.108Z\n",
      "77\n",
      "114\n",
      "113\n",
      "113\n",
      "114\n",
      "1\n",
      "0\n",
      "9\n",
      "104\n",
      "2017-04-06T11:59:57.341Z\n",
      "2017-04-06T12:00:27.341Z\n",
      "67\n",
      "115\n",
      "114\n",
      "114\n",
      "115\n",
      "7\n",
      "0\n",
      "41\n",
      "67\n",
      "2017-04-06T12:00:54.250Z\n",
      "2017-04-06T12:01:24.250Z\n",
      "58\n",
      "106\n",
      "105\n",
      "105\n",
      "106\n",
      "4\n",
      "1\n",
      "35\n",
      "66\n",
      "2017-04-06T12:01:58.309Z\n",
      "2017-04-06T12:02:28.309Z\n",
      "53\n",
      "108\n",
      "107\n",
      "107\n",
      "108\n",
      "6\n",
      "0\n",
      "44\n",
      "58\n",
      "2017-04-06T12:02:58.517Z\n",
      "2017-04-06T12:03:28.517Z\n",
      "74\n",
      "125\n",
      "124\n",
      "124\n",
      "125\n",
      "2\n",
      "3\n",
      "50\n",
      "70\n",
      "2017-04-06T12:03:40.850Z\n",
      "2017-04-06T12:04:10.850Z\n",
      "58\n",
      "113\n",
      "112\n",
      "112\n",
      "113\n",
      "2\n",
      "2\n",
      "65\n",
      "44\n",
      "2017-04-06T12:04:27.392Z\n",
      "2017-04-06T12:04:57.392Z\n",
      "63\n",
      "115\n",
      "114\n",
      "114\n",
      "115\n",
      "1\n",
      "2\n",
      "57\n",
      "55\n",
      "Anon05\n",
      "../Data_Publish/Data_WebGazer/Data_ProcessedByScript02/Anon05.csv\n",
      "2017-04-10T14:11:02.076Z\n",
      "2017-04-10T14:11:32.076Z\n",
      "34\n",
      "105\n",
      "104\n",
      "104\n",
      "105\n",
      "4\n",
      "5\n",
      "14\n",
      "82\n",
      "2017-04-10T14:11:56.185Z\n",
      "2017-04-10T14:12:26.185Z\n",
      "53\n",
      "117\n",
      "116\n",
      "116\n",
      "117\n",
      "2\n",
      "5\n",
      "13\n",
      "97\n",
      "2017-04-10T14:12:54.577Z\n",
      "2017-04-10T14:13:24.577Z\n",
      "47\n",
      "114\n",
      "113\n",
      "113\n",
      "114\n",
      "1\n",
      "5\n",
      "12\n",
      "96\n",
      "2017-04-10T14:13:26.268Z\n",
      "2017-04-10T14:13:56.268Z\n",
      "48\n",
      "119\n",
      "118\n",
      "118\n",
      "119\n",
      "2\n",
      "5\n",
      "19\n",
      "93\n",
      "2017-04-10T14:14:28.124Z\n",
      "2017-04-10T14:14:58.124Z\n",
      "52\n",
      "120\n",
      "119\n",
      "119\n",
      "120\n",
      "0\n",
      "0\n",
      "18\n",
      "102\n",
      "2017-04-10T14:15:14.298Z\n",
      "2017-04-10T14:15:44.298Z\n",
      "36\n",
      "100\n",
      "99\n",
      "99\n",
      "100\n",
      "3\n",
      "4\n",
      "17\n",
      "76\n",
      "2017-04-10T14:15:59.063Z\n",
      "2017-04-10T14:16:29.063Z\n",
      "42\n",
      "117\n",
      "116\n",
      "116\n",
      "117\n",
      "2\n",
      "2\n",
      "6\n",
      "107\n",
      "2017-04-10T14:21:43.014Z\n",
      "2017-04-10T14:22:13.014Z\n",
      "30\n",
      "79\n",
      "78\n",
      "78\n",
      "79\n",
      "1\n",
      "0\n",
      "4\n",
      "74\n",
      "2017-04-10T14:22:52.041Z\n",
      "2017-04-10T14:23:22.041Z\n",
      "67\n",
      "139\n",
      "138\n",
      "138\n",
      "139\n",
      "0\n",
      "1\n",
      "6\n",
      "132\n",
      "2017-04-10T14:23:47.919Z\n",
      "2017-04-10T14:24:17.919Z\n",
      "72\n",
      "138\n",
      "137\n",
      "137\n",
      "138\n",
      "1\n",
      "0\n",
      "2\n",
      "135\n",
      "2017-04-10T14:24:42.221Z\n",
      "2017-04-10T14:25:12.221Z\n",
      "71\n",
      "142\n",
      "141\n",
      "141\n",
      "142\n",
      "3\n",
      "1\n",
      "1\n",
      "137\n",
      "2017-04-10T14:25:48.228Z\n",
      "2017-04-10T14:26:18.228Z\n",
      "45\n",
      "121\n",
      "120\n",
      "120\n",
      "121\n",
      "1\n",
      "7\n",
      "10\n",
      "103\n",
      "2017-04-10T14:26:53.561Z\n",
      "2017-04-10T14:27:23.561Z\n",
      "51\n",
      "144\n",
      "143\n",
      "143\n",
      "144\n",
      "1\n",
      "1\n",
      "5\n",
      "137\n",
      "2017-04-10T14:27:39.525Z\n",
      "2017-04-10T14:28:09.525Z\n",
      "60\n",
      "143\n",
      "142\n",
      "142\n",
      "143\n",
      "0\n",
      "2\n",
      "2\n",
      "139\n",
      "2017-04-10T14:28:43.921Z\n",
      "2017-04-10T14:29:13.921Z\n",
      "38\n",
      "140\n",
      "139\n",
      "139\n",
      "140\n",
      "0\n",
      "0\n",
      "0\n",
      "140\n",
      "Anon06\n",
      "../Data_Publish/Data_WebGazer/Data_ProcessedByScript02/Anon06.csv\n",
      "2017-04-10T15:57:29.408Z\n",
      "2017-04-10T15:57:59.408Z\n",
      "55\n",
      "110\n",
      "109\n",
      "109\n",
      "110\n",
      "2\n",
      "10\n",
      "17\n",
      "81\n",
      "2017-04-10T15:58:28.891Z\n",
      "2017-04-10T15:58:58.891Z\n",
      "48\n",
      "100\n",
      "99\n",
      "99\n",
      "100\n",
      "0\n",
      "5\n",
      "9\n",
      "86\n",
      "2017-04-10T15:59:30.872Z\n",
      "2017-04-10T16:00:00.872Z\n",
      "44\n",
      "97\n",
      "96\n",
      "96\n",
      "97\n",
      "2\n",
      "3\n",
      "6\n",
      "86\n",
      "2017-04-10T16:00:29.310Z\n",
      "2017-04-10T16:00:59.310Z\n",
      "50\n",
      "110\n",
      "109\n",
      "109\n",
      "110\n",
      "2\n",
      "10\n",
      "11\n",
      "87\n",
      "2017-04-10T16:01:31.757Z\n",
      "2017-04-10T16:02:01.757Z\n",
      "52\n",
      "98\n",
      "97\n",
      "97\n",
      "98\n",
      "0\n",
      "0\n",
      "0\n",
      "98\n",
      "2017-04-10T16:02:19.055Z\n",
      "2017-04-10T16:02:49.055Z\n",
      "35\n",
      "93\n",
      "92\n",
      "92\n",
      "93\n",
      "0\n",
      "9\n",
      "2\n",
      "82\n",
      "2017-04-10T16:03:01.872Z\n",
      "2017-04-10T16:03:31.872Z\n",
      "40\n",
      "95\n",
      "94\n",
      "94\n",
      "95\n",
      "0\n",
      "5\n",
      "2\n",
      "88\n",
      "2017-04-10T16:08:46.041Z\n",
      "2017-04-10T16:09:16.041Z\n",
      "42\n",
      "71\n",
      "70\n",
      "70\n",
      "71\n",
      "0\n",
      "1\n",
      "1\n",
      "69\n",
      "2017-04-10T16:09:55.699Z\n",
      "2017-04-10T16:10:25.699Z\n",
      "41\n",
      "75\n",
      "74\n",
      "74\n",
      "75\n",
      "0\n",
      "1\n",
      "0\n",
      "74\n",
      "2017-04-10T16:10:58.126Z\n",
      "2017-04-10T16:11:28.126Z\n",
      "44\n",
      "72\n",
      "71\n",
      "71\n",
      "72\n",
      "0\n",
      "0\n",
      "1\n",
      "71\n",
      "2017-04-10T16:11:46.650Z\n",
      "2017-04-10T16:12:16.650Z\n",
      "43\n",
      "75\n",
      "74\n",
      "74\n",
      "75\n",
      "0\n",
      "0\n",
      "3\n",
      "72\n",
      "2017-04-10T16:12:48.536Z\n",
      "2017-04-10T16:13:18.536Z\n",
      "52\n",
      "75\n",
      "74\n",
      "74\n",
      "75\n",
      "0\n",
      "1\n",
      "1\n",
      "73\n",
      "2017-04-10T16:13:40.998Z\n",
      "2017-04-10T16:14:10.998Z\n",
      "52\n",
      "74\n",
      "73\n",
      "73\n",
      "74\n",
      "0\n",
      "2\n",
      "2\n",
      "70\n",
      "2017-04-10T16:14:32.751Z\n",
      "2017-04-10T16:15:02.751Z\n",
      "53\n",
      "83\n",
      "82\n",
      "82\n",
      "83\n",
      "1\n",
      "2\n",
      "2\n",
      "78\n",
      "2017-04-10T16:15:36.751Z\n",
      "2017-04-10T16:16:06.751Z\n",
      "42\n",
      "75\n",
      "74\n",
      "74\n",
      "75\n",
      "0\n",
      "1\n",
      "2\n",
      "72\n",
      "Anon07\n",
      "../Data_Publish/Data_WebGazer/Data_ProcessedByScript02/Anon07.csv\n",
      "2017-04-13T12:39:08.513Z\n",
      "2017-04-13T12:39:38.513Z\n",
      "74\n",
      "130\n",
      "129\n",
      "129\n",
      "130\n",
      "0\n",
      "5\n",
      "36\n",
      "89\n",
      "2017-04-13T12:40:00.079Z\n",
      "2017-04-13T12:40:30.079Z\n",
      "76\n",
      "123\n",
      "122\n",
      "122\n",
      "123\n",
      "3\n",
      "2\n",
      "17\n",
      "101\n",
      "2017-04-13T12:41:09.198Z\n",
      "2017-04-13T12:41:39.198Z\n",
      "71\n",
      "117\n",
      "116\n",
      "116\n",
      "117\n",
      "2\n",
      "6\n",
      "26\n",
      "83\n",
      "2017-04-13T12:42:16.846Z\n",
      "2017-04-13T12:42:46.846Z\n",
      "93\n",
      "141\n",
      "140\n",
      "140\n",
      "141\n",
      "1\n",
      "1\n",
      "15\n",
      "124\n",
      "2017-04-13T12:43:15.895Z\n",
      "2017-04-13T12:43:45.895Z\n",
      "70\n",
      "133\n",
      "132\n",
      "132\n",
      "133\n",
      "0\n",
      "1\n",
      "12\n",
      "120\n",
      "2017-04-13T12:44:12.455Z\n",
      "2017-04-13T12:44:42.455Z\n",
      "80\n",
      "134\n",
      "133\n",
      "133\n",
      "134\n",
      "0\n",
      "3\n",
      "10\n",
      "121\n",
      "2017-04-13T12:52:11.945Z\n",
      "2017-04-13T12:52:41.945Z\n",
      "66\n",
      "109\n",
      "108\n",
      "108\n",
      "109\n",
      "0\n",
      "12\n",
      "22\n",
      "75\n",
      "2017-04-13T12:53:03.880Z\n",
      "2017-04-13T12:53:33.880Z\n",
      "85\n",
      "120\n",
      "119\n",
      "119\n",
      "120\n",
      "2\n",
      "2\n",
      "38\n",
      "78\n",
      "2017-04-13T12:54:06.429Z\n",
      "2017-04-13T12:54:36.429Z\n",
      "65\n",
      "131\n",
      "130\n",
      "130\n",
      "131\n",
      "4\n",
      "4\n",
      "33\n",
      "90\n",
      "2017-04-13T12:55:10.778Z\n",
      "2017-04-13T12:55:40.778Z\n",
      "100\n",
      "137\n",
      "136\n",
      "136\n",
      "137\n",
      "0\n",
      "10\n",
      "21\n",
      "106\n",
      "2017-04-13T12:56:04.060Z\n",
      "2017-04-13T12:56:34.060Z\n",
      "75\n",
      "127\n",
      "126\n",
      "126\n",
      "127\n",
      "0\n",
      "2\n",
      "20\n",
      "105\n",
      "2017-04-13T12:57:01.542Z\n",
      "2017-04-13T12:57:31.542Z\n",
      "81\n",
      "123\n",
      "122\n",
      "122\n",
      "123\n",
      "1\n",
      "1\n",
      "14\n",
      "107\n",
      "2017-04-13T12:58:09.485Z\n",
      "2017-04-13T12:58:39.485Z\n",
      "86\n",
      "125\n",
      "124\n",
      "124\n",
      "125\n",
      "3\n",
      "2\n",
      "23\n",
      "97\n",
      "2017-04-13T12:58:51.940Z\n",
      "2017-04-13T12:59:21.940Z\n",
      "98\n",
      "134\n",
      "133\n",
      "133\n",
      "134\n",
      "0\n",
      "4\n",
      "23\n",
      "107\n",
      "Anon08\n",
      "../Data_Publish/Data_WebGazer/Data_ProcessedByScript02/Anon08.csv\n",
      "2017-04-12T12:15:41.689Z\n",
      "2017-04-12T12:16:11.689Z\n",
      "58\n",
      "128\n",
      "127\n",
      "127\n",
      "128\n",
      "1\n",
      "11\n",
      "10\n",
      "106\n",
      "2017-04-12T12:16:29.335Z\n",
      "2017-04-12T12:16:59.335Z\n",
      "51\n",
      "125\n",
      "124\n",
      "124\n",
      "125\n",
      "0\n",
      "8\n",
      "8\n",
      "109\n",
      "2017-04-12T12:17:30.737Z\n",
      "2017-04-12T12:18:00.737Z\n",
      "57\n",
      "137\n",
      "136\n",
      "136\n",
      "137\n",
      "1\n",
      "9\n",
      "19\n",
      "108\n",
      "2017-04-12T12:18:39.501Z\n",
      "2017-04-12T12:19:09.501Z\n",
      "49\n",
      "134\n",
      "133\n",
      "133\n",
      "134\n",
      "0\n",
      "18\n",
      "19\n",
      "97\n",
      "2017-04-12T12:19:40.778Z\n",
      "2017-04-12T12:20:10.778Z\n",
      "47\n",
      "128\n",
      "127\n",
      "127\n",
      "128\n",
      "2\n",
      "20\n",
      "10\n",
      "96\n",
      "2017-04-12T12:20:22.356Z\n",
      "2017-04-12T12:20:52.356Z\n",
      "46\n",
      "129\n",
      "128\n",
      "128\n",
      "129\n",
      "1\n",
      "13\n",
      "8\n",
      "107\n",
      "2017-04-12T12:21:18.519Z\n",
      "2017-04-12T12:21:48.519Z\n",
      "43\n",
      "130\n",
      "129\n",
      "129\n",
      "130\n",
      "0\n",
      "9\n",
      "14\n",
      "107\n",
      "2017-04-12T12:26:56.893Z\n",
      "2017-04-12T12:27:26.893Z\n",
      "50\n",
      "127\n",
      "126\n",
      "126\n",
      "127\n",
      "0\n",
      "8\n",
      "8\n",
      "111\n",
      "2017-04-12T12:27:56.694Z\n",
      "2017-04-12T12:28:26.694Z\n",
      "34\n",
      "119\n",
      "118\n",
      "118\n",
      "119\n",
      "0\n",
      "7\n",
      "3\n",
      "109\n",
      "2017-04-12T12:28:51.981Z\n",
      "2017-04-12T12:29:21.981Z\n",
      "35\n",
      "119\n",
      "118\n",
      "118\n",
      "119\n",
      "0\n",
      "8\n",
      "4\n",
      "107\n",
      "2017-04-12T12:30:01.895Z\n",
      "2017-04-12T12:30:31.895Z\n",
      "52\n",
      "131\n",
      "130\n",
      "130\n",
      "131\n",
      "1\n",
      "8\n",
      "3\n",
      "119\n",
      "2017-04-12T12:30:58.653Z\n",
      "2017-04-12T12:31:28.653Z\n",
      "45\n",
      "126\n",
      "125\n",
      "125\n",
      "126\n",
      "0\n",
      "14\n",
      "3\n",
      "109\n",
      "2017-04-12T12:31:49.591Z\n",
      "2017-04-12T12:32:19.591Z\n",
      "49\n",
      "126\n",
      "125\n",
      "125\n",
      "126\n",
      "0\n",
      "7\n",
      "5\n",
      "114\n",
      "2017-04-12T12:32:29.686Z\n",
      "2017-04-12T12:32:59.686Z\n",
      "42\n",
      "129\n",
      "128\n",
      "128\n",
      "129\n",
      "4\n",
      "11\n",
      "12\n",
      "102\n",
      "2017-04-12T12:33:15.617Z\n",
      "2017-04-12T12:33:45.617Z\n",
      "60\n",
      "129\n",
      "128\n",
      "128\n",
      "129\n",
      "0\n",
      "17\n",
      "10\n",
      "102\n",
      "Anon09\n",
      "../Data_Publish/Data_WebGazer/Data_ProcessedByScript02/Anon09.csv\n",
      "2017-04-11T09:19:45.229Z\n",
      "2017-04-11T09:20:15.229Z\n",
      "56\n",
      "105\n",
      "104\n",
      "104\n",
      "105\n",
      "1\n",
      "3\n",
      "15\n",
      "86\n",
      "2017-04-11T09:20:51.675Z\n",
      "2017-04-11T09:21:21.675Z\n",
      "60\n",
      "119\n",
      "118\n",
      "118\n",
      "119\n",
      "0\n",
      "7\n",
      "24\n",
      "88\n",
      "2017-04-11T09:21:39.330Z\n",
      "2017-04-11T09:22:09.330Z\n",
      "55\n",
      "119\n",
      "118\n",
      "118\n",
      "119\n",
      "0\n",
      "0\n",
      "0\n",
      "119\n",
      "2017-04-11T09:22:38.175Z\n",
      "2017-04-11T09:23:08.175Z\n",
      "51\n",
      "116\n",
      "115\n",
      "115\n",
      "116\n",
      "0\n",
      "1\n",
      "0\n",
      "115\n",
      "2017-04-11T09:23:25.347Z\n",
      "2017-04-11T09:23:55.347Z\n",
      "70\n",
      "129\n",
      "128\n",
      "128\n",
      "129\n",
      "1\n",
      "0\n",
      "1\n",
      "127\n",
      "2017-04-11T09:24:12.007Z\n",
      "2017-04-11T09:24:42.007Z\n",
      "78\n",
      "130\n",
      "129\n",
      "129\n",
      "130\n",
      "0\n",
      "0\n",
      "0\n",
      "130\n",
      "2017-04-11T09:24:58.350Z\n",
      "2017-04-11T09:25:28.350Z\n",
      "59\n",
      "121\n",
      "120\n",
      "120\n",
      "121\n",
      "0\n",
      "1\n",
      "0\n",
      "120\n",
      "2017-04-11T09:29:56.268Z\n",
      "2017-04-11T09:30:26.268Z\n",
      "67\n",
      "137\n",
      "136\n",
      "136\n",
      "137\n",
      "4\n",
      "8\n",
      "8\n",
      "117\n",
      "2017-04-11T09:30:58.334Z\n",
      "2017-04-11T09:31:28.334Z\n",
      "71\n",
      "139\n",
      "138\n",
      "138\n",
      "139\n",
      "1\n",
      "2\n",
      "10\n",
      "126\n",
      "2017-04-11T09:31:46.269Z\n",
      "2017-04-11T09:32:16.269Z\n",
      "69\n",
      "139\n",
      "138\n",
      "138\n",
      "139\n",
      "1\n",
      "6\n",
      "8\n",
      "124\n",
      "2017-04-11T09:32:51.660Z\n",
      "2017-04-11T09:33:21.660Z\n",
      "76\n",
      "133\n",
      "132\n",
      "132\n",
      "133\n",
      "1\n",
      "4\n",
      "1\n",
      "127\n",
      "2017-04-11T09:33:42.732Z\n",
      "2017-04-11T09:34:12.732Z\n",
      "68\n",
      "128\n",
      "127\n",
      "127\n",
      "128\n",
      "1\n",
      "9\n",
      "6\n",
      "112\n",
      "2017-04-11T09:34:19.886Z\n",
      "2017-04-11T09:34:49.886Z\n",
      "74\n",
      "132\n",
      "131\n",
      "131\n",
      "132\n",
      "6\n",
      "9\n",
      "11\n",
      "106\n",
      "2017-04-11T09:35:10.043Z\n",
      "2017-04-11T09:35:40.043Z\n",
      "94\n",
      "140\n",
      "139\n",
      "139\n",
      "140\n",
      "2\n",
      "6\n",
      "4\n",
      "128\n",
      "2017-04-11T09:35:53.486Z\n",
      "2017-04-11T09:36:23.486Z\n",
      "85\n",
      "135\n",
      "134\n",
      "134\n",
      "135\n",
      "3\n",
      "7\n",
      "13\n",
      "112\n",
      "2017-04-11T09:36:41.531Z\n",
      "2017-04-11T09:37:11.531Z\n",
      "74\n",
      "124\n",
      "123\n",
      "123\n",
      "124\n",
      "4\n",
      "7\n",
      "14\n",
      "99\n",
      "Anon10\n",
      "../Data_Publish/Data_WebGazer/Data_ProcessedByScript02/Anon10.csv\n",
      "2017-04-11T10:47:11.338Z\n",
      "2017-04-11T10:47:41.338Z\n",
      "89\n",
      "140\n",
      "139\n",
      "139\n",
      "140\n",
      "2\n",
      "15\n",
      "6\n",
      "117\n",
      "2017-04-11T10:48:05.402Z\n",
      "2017-04-11T10:48:35.402Z\n",
      "94\n",
      "137\n",
      "136\n",
      "136\n",
      "137\n",
      "0\n",
      "5\n",
      "8\n",
      "124\n",
      "2017-04-11T10:49:09.290Z\n",
      "2017-04-11T10:49:39.290Z\n",
      "79\n",
      "130\n",
      "129\n",
      "129\n",
      "130\n",
      "0\n",
      "14\n",
      "3\n",
      "113\n",
      "2017-04-11T10:50:02.853Z\n",
      "2017-04-11T10:50:32.853Z\n",
      "102\n",
      "139\n",
      "138\n",
      "138\n",
      "139\n",
      "0\n",
      "8\n",
      "2\n",
      "129\n",
      "2017-04-11T10:50:56.553Z\n",
      "2017-04-11T10:51:26.553Z\n",
      "81\n",
      "123\n",
      "122\n",
      "122\n",
      "123\n",
      "0\n",
      "4\n",
      "0\n",
      "119\n",
      "2017-04-11T10:51:34.947Z\n",
      "2017-04-11T10:52:04.947Z\n",
      "93\n",
      "134\n",
      "133\n",
      "133\n",
      "134\n",
      "0\n",
      "7\n",
      "15\n",
      "112\n",
      "2017-04-11T10:52:20.467Z\n",
      "2017-04-11T10:52:50.467Z\n",
      "82\n",
      "130\n",
      "129\n",
      "129\n",
      "130\n",
      "0\n",
      "3\n",
      "0\n",
      "127\n",
      "2017-04-11T10:53:23.970Z\n",
      "2017-04-11T10:53:53.970Z\n",
      "78\n",
      "133\n",
      "132\n",
      "132\n",
      "133\n",
      "0\n",
      "6\n",
      "3\n",
      "124\n",
      "2017-04-11T10:54:08.440Z\n",
      "2017-04-11T10:54:38.440Z\n",
      "93\n",
      "141\n",
      "140\n",
      "140\n",
      "141\n",
      "0\n",
      "2\n",
      "0\n",
      "139\n",
      "2017-04-11T10:58:40.598Z\n",
      "2017-04-11T10:59:10.598Z\n",
      "68\n",
      "139\n",
      "138\n",
      "138\n",
      "139\n",
      "3\n",
      "8\n",
      "27\n",
      "101\n",
      "2017-04-11T10:59:22.671Z\n",
      "2017-04-11T10:59:52.671Z\n",
      "59\n",
      "139\n",
      "138\n",
      "138\n",
      "139\n",
      "2\n",
      "10\n",
      "13\n",
      "114\n",
      "2017-04-11T11:00:24.587Z\n",
      "2017-04-11T11:00:54.587Z\n",
      "64\n",
      "139\n",
      "138\n",
      "138\n",
      "139\n",
      "4\n",
      "4\n",
      "15\n",
      "116\n",
      "2017-04-11T11:01:22.793Z\n",
      "2017-04-11T11:01:52.793Z\n",
      "56\n",
      "129\n",
      "128\n",
      "128\n",
      "129\n",
      "0\n",
      "1\n",
      "19\n",
      "109\n",
      "2017-04-11T11:02:05.365Z\n",
      "2017-04-11T11:02:35.365Z\n",
      "49\n",
      "118\n",
      "117\n",
      "117\n",
      "118\n",
      "0\n",
      "3\n",
      "21\n",
      "94\n",
      "2017-04-11T11:02:58.654Z\n",
      "2017-04-11T11:03:28.654Z\n",
      "60\n",
      "123\n",
      "122\n",
      "122\n",
      "123\n",
      "0\n",
      "2\n",
      "14\n",
      "107\n",
      "2017-04-11T11:04:07.884Z\n",
      "2017-04-11T11:04:37.884Z\n",
      "62\n",
      "119\n",
      "118\n",
      "118\n",
      "119\n",
      "0\n",
      "1\n",
      "21\n",
      "97\n",
      "Anon11\n",
      "../Data_Publish/Data_WebGazer/Data_ProcessedByScript02/Anon11.csv\n",
      "2017-04-06T09:44:01.073Z\n",
      "2017-04-06T09:44:31.073Z\n",
      "74\n",
      "125\n",
      "124\n",
      "124\n",
      "125\n",
      "0\n",
      "7\n",
      "16\n",
      "102\n",
      "2017-04-06T09:45:01.704Z\n",
      "2017-04-06T09:45:31.704Z\n",
      "66\n",
      "116\n",
      "115\n",
      "115\n",
      "116\n",
      "0\n",
      "3\n",
      "10\n",
      "103\n",
      "2017-04-06T09:45:57.036Z\n",
      "2017-04-06T09:46:27.036Z\n",
      "77\n",
      "139\n",
      "138\n",
      "138\n",
      "139\n",
      "0\n",
      "1\n",
      "17\n",
      "121\n",
      "2017-04-06T09:46:34.970Z\n",
      "2017-04-06T09:47:04.970Z\n",
      "89\n",
      "139\n",
      "138\n",
      "138\n",
      "139\n",
      "0\n",
      "6\n",
      "15\n",
      "118\n",
      "2017-04-06T09:47:14.614Z\n",
      "2017-04-06T09:47:44.614Z\n",
      "91\n",
      "135\n",
      "134\n",
      "134\n",
      "135\n",
      "0\n",
      "4\n",
      "11\n",
      "120\n",
      "2017-04-06T09:47:56.285Z\n",
      "2017-04-06T09:48:26.285Z\n",
      "71\n",
      "132\n",
      "131\n",
      "131\n",
      "132\n",
      "0\n",
      "0\n",
      "2\n",
      "130\n",
      "2017-04-06T09:49:03.751Z\n",
      "2017-04-06T09:49:33.751Z\n",
      "66\n",
      "110\n",
      "109\n",
      "109\n",
      "110\n",
      "0\n",
      "1\n",
      "0\n",
      "109\n",
      "2017-04-06T09:50:06.501Z\n",
      "2017-04-06T09:50:36.501Z\n",
      "77\n",
      "131\n",
      "130\n",
      "130\n",
      "131\n",
      "0\n",
      "5\n",
      "2\n",
      "124\n",
      "2017-04-06T09:50:50.318Z\n",
      "2017-04-06T09:51:20.318Z\n",
      "90\n",
      "144\n",
      "143\n",
      "143\n",
      "144\n",
      "0\n",
      "5\n",
      "4\n",
      "135\n",
      "2017-04-06T09:55:47.437Z\n",
      "2017-04-06T09:56:17.437Z\n",
      "51\n",
      "140\n",
      "139\n",
      "139\n",
      "140\n",
      "4\n",
      "4\n",
      "6\n",
      "126\n",
      "2017-04-06T09:56:32.515Z\n",
      "2017-04-06T09:57:02.515Z\n",
      "45\n",
      "134\n",
      "133\n",
      "133\n",
      "134\n",
      "8\n",
      "3\n",
      "8\n",
      "115\n",
      "2017-04-06T09:57:26.172Z\n",
      "2017-04-06T09:57:56.172Z\n",
      "60\n",
      "126\n",
      "125\n",
      "125\n",
      "126\n",
      "5\n",
      "1\n",
      "4\n",
      "116\n",
      "2017-04-06T09:58:21.711Z\n",
      "2017-04-06T09:58:51.711Z\n",
      "52\n",
      "124\n",
      "123\n",
      "123\n",
      "124\n",
      "2\n",
      "7\n",
      "19\n",
      "96\n",
      "2017-04-06T09:58:53.203Z\n",
      "2017-04-06T09:59:23.203Z\n",
      "48\n",
      "128\n",
      "127\n",
      "127\n",
      "128\n",
      "1\n",
      "9\n",
      "21\n",
      "97\n",
      "2017-04-06T10:00:01.508Z\n",
      "2017-04-06T10:00:31.508Z\n",
      "63\n",
      "123\n",
      "122\n",
      "122\n",
      "123\n",
      "0\n",
      "2\n",
      "14\n",
      "107\n",
      "2017-04-06T10:00:54.302Z\n",
      "2017-04-06T10:01:24.302Z\n",
      "64\n",
      "125\n",
      "124\n",
      "124\n",
      "125\n",
      "1\n",
      "0\n",
      "27\n",
      "97\n",
      "Anon12\n",
      "../Data_Publish/Data_WebGazer/Data_ProcessedByScript02/Anon12.csv\n",
      "2017-04-12T15:30:24.522Z\n",
      "2017-04-12T15:30:54.522Z\n",
      "58\n",
      "128\n",
      "127\n",
      "127\n",
      "128\n",
      "1\n",
      "15\n",
      "32\n",
      "80\n",
      "2017-04-12T15:31:26.345Z\n",
      "2017-04-12T15:31:56.345Z\n",
      "63\n",
      "123\n",
      "122\n",
      "122\n",
      "123\n",
      "2\n",
      "13\n",
      "10\n",
      "98\n",
      "2017-04-12T15:32:26.192Z\n",
      "2017-04-12T15:32:56.192Z\n",
      "57\n",
      "110\n",
      "109\n",
      "109\n",
      "110\n",
      "4\n",
      "2\n",
      "51\n",
      "53\n",
      "2017-04-12T15:33:18.919Z\n",
      "2017-04-12T15:33:48.919Z\n",
      "71\n",
      "122\n",
      "121\n",
      "121\n",
      "122\n",
      "6\n",
      "5\n",
      "45\n",
      "66\n",
      "2017-04-12T15:34:26.957Z\n",
      "2017-04-12T15:34:56.957Z\n",
      "69\n",
      "130\n",
      "129\n",
      "129\n",
      "130\n",
      "8\n",
      "4\n",
      "67\n",
      "51\n",
      "2017-04-12T15:35:10.491Z\n",
      "2017-04-12T15:35:40.491Z\n",
      "65\n",
      "131\n",
      "130\n",
      "130\n",
      "131\n",
      "7\n",
      "2\n",
      "36\n",
      "86\n",
      "2017-04-12T15:36:08.710Z\n",
      "2017-04-12T15:36:38.710Z\n",
      "53\n",
      "109\n",
      "108\n",
      "108\n",
      "109\n",
      "0\n",
      "4\n",
      "20\n",
      "85\n",
      "2017-04-12T15:40:33.484Z\n",
      "2017-04-12T15:41:03.484Z\n",
      "58\n",
      "134\n",
      "133\n",
      "133\n",
      "134\n",
      "11\n",
      "11\n",
      "39\n",
      "73\n",
      "2017-04-12T15:41:40.026Z\n",
      "2017-04-12T15:42:10.026Z\n",
      "68\n",
      "132\n",
      "131\n",
      "131\n",
      "132\n",
      "11\n",
      "6\n",
      "52\n",
      "63\n",
      "2017-04-12T15:42:32.751Z\n",
      "2017-04-12T15:43:02.751Z\n",
      "53\n",
      "133\n",
      "132\n",
      "132\n",
      "133\n",
      "9\n",
      "5\n",
      "59\n",
      "60\n",
      "2017-04-12T15:43:13.927Z\n",
      "2017-04-12T15:43:43.927Z\n",
      "78\n",
      "151\n",
      "150\n",
      "150\n",
      "151\n",
      "9\n",
      "2\n",
      "39\n",
      "101\n",
      "2017-04-12T15:44:12.550Z\n",
      "2017-04-12T15:44:42.550Z\n",
      "55\n",
      "138\n",
      "137\n",
      "137\n",
      "138\n",
      "8\n",
      "5\n",
      "31\n",
      "94\n",
      "2017-04-12T15:45:20.815Z\n",
      "2017-04-12T15:45:50.815Z\n",
      "65\n",
      "149\n",
      "148\n",
      "148\n",
      "149\n",
      "10\n",
      "13\n",
      "39\n",
      "87\n",
      "2017-04-12T15:46:08.769Z\n",
      "2017-04-12T15:46:38.769Z\n",
      "59\n",
      "142\n",
      "141\n",
      "141\n",
      "142\n",
      "2\n",
      "8\n",
      "57\n",
      "75\n",
      "2017-04-12T15:47:09.125Z\n",
      "2017-04-12T15:47:39.125Z\n",
      "62\n",
      "137\n",
      "136\n",
      "136\n",
      "137\n",
      "4\n",
      "5\n",
      "61\n",
      "67\n",
      "Anon13\n",
      "../Data_Publish/Data_WebGazer/Data_ProcessedByScript02/Anon13.csv\n",
      "2017-04-12T14:25:10.251Z\n",
      "2017-04-12T14:25:40.251Z\n",
      "59\n",
      "133\n",
      "132\n",
      "132\n",
      "133\n",
      "1\n",
      "0\n",
      "59\n",
      "73\n",
      "2017-04-12T14:26:17.218Z\n",
      "2017-04-12T14:26:47.218Z\n",
      "62\n",
      "121\n",
      "120\n",
      "120\n",
      "121\n",
      "2\n",
      "1\n",
      "77\n",
      "41\n",
      "2017-04-12T14:27:20.925Z\n",
      "2017-04-12T14:27:50.925Z\n",
      "75\n",
      "131\n",
      "130\n",
      "130\n",
      "131\n",
      "8\n",
      "0\n",
      "66\n",
      "57\n",
      "2017-04-12T14:28:16.755Z\n",
      "2017-04-12T14:28:46.755Z\n",
      "84\n",
      "134\n",
      "133\n",
      "133\n",
      "134\n",
      "0\n",
      "7\n",
      "47\n",
      "80\n",
      "2017-04-12T14:29:19.997Z\n",
      "2017-04-12T14:29:49.997Z\n",
      "74\n",
      "130\n",
      "129\n",
      "129\n",
      "130\n",
      "1\n",
      "18\n",
      "40\n",
      "71\n",
      "2017-04-12T14:30:05.695Z\n",
      "2017-04-12T14:30:35.695Z\n",
      "69\n",
      "129\n",
      "128\n",
      "128\n",
      "129\n",
      "0\n",
      "3\n",
      "50\n",
      "76\n",
      "2017-04-12T14:30:53.287Z\n",
      "2017-04-12T14:31:23.287Z\n",
      "79\n",
      "129\n",
      "128\n",
      "128\n",
      "129\n",
      "1\n",
      "3\n",
      "62\n",
      "63\n",
      "2017-04-12T14:31:54.439Z\n",
      "2017-04-12T14:32:24.439Z\n",
      "78\n",
      "140\n",
      "139\n",
      "139\n",
      "140\n",
      "7\n",
      "4\n",
      "61\n",
      "68\n",
      "2017-04-12T14:36:50.732Z\n",
      "2017-04-12T14:37:20.732Z\n",
      "55\n",
      "132\n",
      "131\n",
      "131\n",
      "132\n",
      "2\n",
      "19\n",
      "42\n",
      "69\n",
      "2017-04-12T14:37:54.699Z\n",
      "2017-04-12T14:38:24.699Z\n",
      "57\n",
      "128\n",
      "127\n",
      "127\n",
      "128\n",
      "14\n",
      "11\n",
      "32\n",
      "71\n",
      "2017-04-12T14:38:39.619Z\n",
      "2017-04-12T14:39:09.619Z\n",
      "54\n",
      "126\n",
      "125\n",
      "125\n",
      "126\n",
      "6\n",
      "9\n",
      "42\n",
      "69\n",
      "2017-04-12T14:39:33.407Z\n",
      "2017-04-12T14:40:03.407Z\n",
      "83\n",
      "144\n",
      "143\n",
      "143\n",
      "144\n",
      "11\n",
      "14\n",
      "29\n",
      "90\n",
      "2017-04-12T14:40:24.573Z\n",
      "2017-04-12T14:40:54.573Z\n",
      "70\n",
      "137\n",
      "136\n",
      "136\n",
      "137\n",
      "11\n",
      "7\n",
      "41\n",
      "78\n",
      "2017-04-12T14:41:12.434Z\n",
      "2017-04-12T14:41:42.434Z\n",
      "76\n",
      "134\n",
      "133\n",
      "133\n",
      "134\n",
      "10\n",
      "12\n",
      "41\n",
      "71\n",
      "2017-04-12T14:42:19.270Z\n",
      "2017-04-12T14:42:49.270Z\n",
      "73\n",
      "115\n",
      "114\n",
      "114\n",
      "115\n",
      "3\n",
      "14\n",
      "42\n",
      "56\n",
      "(200, 61)\n"
     ]
    }
   ],
   "source": [
    "# Data format: id, starttime_iso, endtime_iso, feature 1, feature 2.......\n",
    "import math\n",
    "from scipy.stats import kurtosis\n",
    "from scipy.stats import skew\n",
    "\n",
    "df_features = pd.DataFrame()\n",
    "\n",
    "for i in range(0, len(list_id_report)):\n",
    "    # id\n",
    "    id_str = list_id_report[i]\n",
    "    print id_str\n",
    "    df_reports_withid = df_reports.loc[df_reports['id'] == id_str]\n",
    "    \n",
    "    ## Read the tsv file based on id_str\n",
    "    path_gazedata_rprocessed = os.path.join(folderpath_webgazerdata_rprocessed, id_str + \".csv\")\n",
    "    print path_gazedata_rprocessed\n",
    "    df_GazeData_rprocessed = DataFrame.from_csv(path_gazedata_rprocessed, sep=\",\")\n",
    "    # print df_GazeData_Tobii.head(5)\n",
    "    df_GazeData_rprocessed = df_GazeData_rprocessed.reset_index()\n",
    "    \n",
    "    ## Remove unnessesary data   \n",
    "    df_GazeData_rprocessed = df_GazeData_rprocessed[['Timestamp_utc',\n",
    "                                                     'FixationIndex',\n",
    "                                                     'GazeEventDuration',\n",
    "                                                     'FixationPointX..MCSpx.',\n",
    "                                                     'FixationPointY..MCSpx.',\n",
    "                                                     'AbsoluteSaccadicDirection']]\n",
    "    df_GazeData_rprocessed.columns = [\"Timestamp_utc\", \n",
    "                                      \"FixationIndex\", \n",
    "                                      \"GazeEventDuration\", \n",
    "                                      \"FixationPointX (MCSpx)\", \n",
    "                                      \"FixationPointY (MCSpx)\",\n",
    "                                      \"AbsoluteSaccadicDirection\"]\n",
    "    \n",
    "    # TODO:change the format of Timestamp_utc\n",
    "    def timestamp_trans(row):\n",
    "        temp_str = row['Timestamp_utc']\n",
    "        temp_str = temp_str+\"Z\"\n",
    "        temp_str = temp_str.replace(\" \", \"T\")\n",
    "        return temp_str\n",
    "    \n",
    "    df_GazeData_rprocessed['Timestamp_utc'] = df_GazeData_rprocessed.apply(timestamp_trans,axis=1)\n",
    "\n",
    "    df_GazeData_Tobii = df_GazeData_rprocessed\n",
    "    \n",
    "    for index, row in df_reports_withid.iterrows():\n",
    "        starttime_iso = row['starttime_iso']\n",
    "        print starttime_iso\n",
    "        endtime_iso = row['endtime_iso']\n",
    "        print endtime_iso\n",
    "        \n",
    "        ## Select Data from df_GazeData_Tobii based on starttime_iso and endtime_iso\n",
    "        df_GazeData_Tobii_selected = df_GazeData_Tobii.loc[((df_GazeData_Tobii['Timestamp_utc'] >= starttime_iso) &\n",
    "                                                           (df_GazeData_Tobii['Timestamp_utc'] <= endtime_iso))\n",
    "                                                          ]\n",
    "        \n",
    "        # print df_GazeData_Tobii_selected.head(20)\n",
    "        # print df_GazeData_Tobii_selected.shape\n",
    "        # print df_GazeData_Tobii_selected.columns\n",
    "        \n",
    "        ## Global Features: Feature Selection based on selected data\n",
    "        temp_fixationindex = 0\n",
    "        temp_timestamp = \"\"\n",
    "        temp_FixationPointX = 0\n",
    "        temp_FixationPointY = 0\n",
    "        list_fixationduration = []\n",
    "        list_saccadeduration = []\n",
    "        list_saccadedistance = []\n",
    "        list_saccadeangel = []\n",
    "        \n",
    "        ## Local Features: Feature Selection based on selected data\n",
    "        \n",
    "        # TODO: get the info about the video and fullscreen playing\n",
    "        video_length = row['video_length']\n",
    "        fullscreen_flag = row['fullscreen']\n",
    "        \n",
    "        face_topleft_x = 0\n",
    "        face_topleft_y = 0\n",
    "        face_bottomright_x = 0\n",
    "        face_bottomright_y = 0\n",
    "                \n",
    "        slide_topleft_x = 0\n",
    "        slide_topleft_y = 0\n",
    "        slide_bottomright_x = 0\n",
    "        slide_bottomright_y = 0\n",
    "                \n",
    "        subtitle_topleft_x = 0\n",
    "        subtitle_topleft_y = 0\n",
    "        subtitle_bottomright_x = 0\n",
    "        subtitle_bottomright_y = 0\n",
    "        \n",
    "        # Select coordinate boundaries for the \n",
    "        if video_length <= 410: # Nucl should be replaced by video_id\n",
    "            if fullscreen_flag:\n",
    "                \n",
    "                face_topleft_x = 1191\n",
    "                face_topleft_y = 239\n",
    "                face_bottomright_x = 1191+331\n",
    "                face_bottomright_y = 239+280\n",
    "                \n",
    "                slide_topleft_x = 137\n",
    "                slide_topleft_y = 132\n",
    "                slide_bottomright_x = 137+929\n",
    "                slide_bottomright_y = 132+557\n",
    "                \n",
    "                subtitle_topleft_x = 402\n",
    "                subtitle_topleft_y = 892\n",
    "                subtitle_bottomright_x = 402+1134\n",
    "                subtitle_bottomright_y = 892+134\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                face_topleft_x = 1089\n",
    "                face_topleft_y = 297\n",
    "                face_bottomright_x = 1089+139\n",
    "                face_bottomright_y = 297+141\n",
    "                \n",
    "                slide_topleft_x = 558\n",
    "                slide_topleft_y = 246\n",
    "                slide_bottomright_x = 558+456\n",
    "                slide_bottomright_y = 246+273\n",
    "                \n",
    "                subtitle_topleft_x = 721\n",
    "                subtitle_topleft_y = 617\n",
    "                subtitle_bottomright_x = 721+478\n",
    "                subtitle_bottomright_y = 617+67\n",
    "        \n",
    "        elif video_length > 450: # Solar\n",
    "            \n",
    "            if fullscreen_flag:\n",
    "                \n",
    "                face_topleft_x = 501\n",
    "                face_topleft_y = 189\n",
    "                face_bottomright_x = 501+267\n",
    "                face_bottomright_y = 189+260\n",
    "                \n",
    "                slide_topleft_x = 861\n",
    "                slide_topleft_y = 313\n",
    "                slide_bottomright_x = 861+811\n",
    "                slide_bottomright_y = 313+483\n",
    "                \n",
    "                subtitle_topleft_x = 458\n",
    "                subtitle_topleft_y = 900\n",
    "                subtitle_bottomright_x = 458+1010\n",
    "                subtitle_bottomright_y = 900+128\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                face_topleft_x = 721\n",
    "                face_topleft_y = 263\n",
    "                face_bottomright_x = 721+146\n",
    "                face_bottomright_y = 263+139\n",
    "                \n",
    "                slide_topleft_x = 913\n",
    "                slide_topleft_y = 330\n",
    "                slide_bottomright_x = 913+401\n",
    "                slide_bottomright_y = 330+241\n",
    "                \n",
    "                subtitle_topleft_x = 709\n",
    "                subtitle_topleft_y = 622\n",
    "                subtitle_bottomright_x = 709+499\n",
    "                subtitle_bottomright_y = 622+60\n",
    "        \n",
    "        ## Define a basic funtion for calculating whether fixations in aoi or not.\n",
    "        def isinaoi(fixation_x, fixation_y):            \n",
    "            if ((fixation_x >= face_topleft_x and fixation_x <= face_bottomright_x) and \n",
    "               (fixation_y >= face_topleft_y and fixation_y <= face_bottomright_y)):\n",
    "                return \"face\"\n",
    "            elif ((fixation_x >= subtitle_topleft_x and fixation_x <= subtitle_bottomright_x) and \n",
    "               (fixation_y >= subtitle_topleft_y and fixation_y <= subtitle_bottomright_y)):\n",
    "                return \"subtitle\"\n",
    "            elif ((fixation_x >= slide_topleft_x and fixation_x <= slide_bottomright_x) and \n",
    "               (fixation_y >= slide_topleft_y and fixation_y <= slide_bottomright_y)): \n",
    "                return \"slide\"\n",
    "            else:\n",
    "                return \"out\"\n",
    "        \n",
    "        ## Define local features\n",
    "        \n",
    "        # num of saccade jump from one area to another\n",
    "        num_saccade_aoi_face_out2in = 0\n",
    "        num_saccade_aoi_face_aoi2in = 0\n",
    "        num_saccade_aoi_face_in2out = 0\n",
    "        num_saccade_aoi_face_in2aoi = 0\n",
    "        num_saccade_aoi_face_within = 0\n",
    "        \n",
    "        num_saccade_aoi_slide_out2in = 0\n",
    "        num_saccade_aoi_slide_aoi2in = 0\n",
    "        num_saccade_aoi_slide_in2out = 0\n",
    "        num_saccade_aoi_slide_in2aoi = 0\n",
    "        num_saccade_aoi_slide_within = 0\n",
    "        \n",
    "        num_saccade_aoi_subtitle_out2in = 0\n",
    "        num_saccade_aoi_subtitle_aoi2in = 0\n",
    "        num_saccade_aoi_subtitle_in2out = 0\n",
    "        num_saccade_aoi_subtitle_in2aoi = 0\n",
    "        num_saccade_aoi_subtitle_within = 0\n",
    "        \n",
    "        temp_aoi = \"out\"\n",
    "        \n",
    "        # numbers and durations of fixations in AOIs.\n",
    "        list_duration_fixation_aoi_face = []\n",
    "        list_duration_fixation_aoi_subtitle = []\n",
    "        list_duration_fixation_aoi_slide = []\n",
    "        # fixations out of AOIs\n",
    "        list_duration_fixation_aoi_out = []\n",
    "        \n",
    "        for index, row in df_GazeData_Tobii_selected.iterrows():\n",
    "            if np.isnan(row['FixationIndex']):\n",
    "                continue\n",
    "            \n",
    "            if temp_fixationindex == 0:\n",
    "                temp_fixationindex = row['FixationIndex']\n",
    "                temp_timestamp = row['Timestamp_utc']\n",
    "                temp_FixationPointX = row['FixationPointX (MCSpx)']\n",
    "                temp_FixationPointY = row['FixationPointY (MCSpx)']\n",
    "                \n",
    "                list_fixationduration.append(row['GazeEventDuration'])\n",
    "                list_saccadeangel.append(row['AbsoluteSaccadicDirection'])\n",
    "                \n",
    "                ## calculate local features\n",
    "                current_aoi = isinaoi(row['FixationPointX (MCSpx)'], row['FixationPointY (MCSpx)'])\n",
    "                if current_aoi == \"face\":\n",
    "                    list_duration_fixation_aoi_face.append(row['GazeEventDuration'])\n",
    "                elif current_aoi == \"subtitle\":\n",
    "                    list_duration_fixation_aoi_subtitle.append(row['GazeEventDuration'])\n",
    "                elif current_aoi == \"slide\":\n",
    "                    list_duration_fixation_aoi_slide.append(row['GazeEventDuration'])\n",
    "                else:\n",
    "                    list_duration_fixation_aoi_out.append(row['GazeEventDuration'])                \n",
    "                temp_aoi = current_aoi\n",
    "            \n",
    "            elif temp_fixationindex != row['FixationIndex']:\n",
    "                \n",
    "                # Global features\n",
    "                temp_fixationindex = row['FixationIndex']\n",
    "                list_fixationduration.append(row['GazeEventDuration'])\n",
    "                list_saccadeangel.append(row['AbsoluteSaccadicDirection'])\n",
    "                \n",
    "                datetime_previous = datetime.datetime.strptime(temp_timestamp, \"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "                datetime_current = datetime.datetime.strptime(row['Timestamp_utc'], \"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "                saccadeduration = datetime_current - datetime_previous\n",
    "                list_saccadeduration.append(float(saccadeduration.total_seconds() * 1000))\n",
    "                \n",
    "                FixationPointX_current = row['FixationPointX (MCSpx)']\n",
    "                FixationPointY_current = row['FixationPointY (MCSpx)']\n",
    "                saccadedistance = math.sqrt(math.pow((FixationPointX_current - temp_FixationPointX), 2) + \n",
    "                                            math.pow((FixationPointY_current - temp_FixationPointY), 2))\n",
    "                list_saccadedistance.append(saccadedistance)\n",
    "                \n",
    "                temp_timestamp = row['Timestamp_utc']\n",
    "                temp_FixationPointX = row['FixationPointX (MCSpx)']\n",
    "                temp_FixationPointY = row['FixationPointY (MCSpx)']\n",
    "                \n",
    "                # Local features\n",
    "                current_aoi = isinaoi(row['FixationPointX (MCSpx)'], row['FixationPointY (MCSpx)'])\n",
    "                \n",
    "                if current_aoi == \"face\":\n",
    "                    \n",
    "                    list_duration_fixation_aoi_face.append(row['GazeEventDuration'])\n",
    "                    \n",
    "                    if temp_aoi == \"face\":\n",
    "                        num_saccade_aoi_face_within = num_saccade_aoi_face_within + 1\n",
    "                    elif temp_aoi == \"out\":\n",
    "                        num_saccade_aoi_face_out2in = num_saccade_aoi_face_out2in + 1\n",
    "                    else:\n",
    "                        num_saccade_aoi_face_aoi2in = num_saccade_aoi_face_aoi2in + 1\n",
    "                        if temp_aoi == \"slide\":\n",
    "                            num_saccade_aoi_slide_in2aoi = num_saccade_aoi_slide_in2aoi + 1\n",
    "                        else:\n",
    "                            num_saccade_aoi_subtitle_in2aoi = num_saccade_aoi_subtitle_in2aoi + 1\n",
    "                        \n",
    "                elif current_aoi == \"subtitle\":\n",
    "                    \n",
    "                    list_duration_fixation_aoi_subtitle.append(row['GazeEventDuration'])\n",
    "                    \n",
    "                    if temp_aoi == \"subtitle\":\n",
    "                        num_saccade_aoi_subtitle_within = num_saccade_aoi_subtitle_within + 1\n",
    "                    elif temp_aoi == \"out\":\n",
    "                        num_saccade_aoi_subtitle_out2in = num_saccade_aoi_subtitle_out2in + 1\n",
    "                    else:\n",
    "                        num_saccade_aoi_subtitle_aoi2in = num_saccade_aoi_subtitle_aoi2in + 1\n",
    "                        if temp_aoi == \"face\":\n",
    "                            num_saccade_aoi_face_in2aoi = num_saccade_aoi_face_in2aoi + 1\n",
    "                        else:\n",
    "                            num_saccade_aoi_slide_in2aoi = num_saccade_aoi_slide_in2aoi + 1\n",
    "                    \n",
    "                elif current_aoi == \"slide\":\n",
    "                    list_duration_fixation_aoi_slide.append(row['GazeEventDuration'])\n",
    "                    \n",
    "                    if temp_aoi == \"slide\":\n",
    "                        num_saccade_aoi_slide_within = num_saccade_aoi_slide_within + 1\n",
    "                    elif temp_aoi == \"out\":\n",
    "                        num_saccade_aoi_slide_out2in = num_saccade_aoi_slide_out2in + 1\n",
    "                    else:\n",
    "                        num_saccade_aoi_subtitle_aoi2in = num_saccade_aoi_subtitle_aoi2in + 1\n",
    "                        if temp_aoi == \"face\":\n",
    "                            num_saccade_aoi_face_in2aoi = num_saccade_aoi_face_in2aoi + 1\n",
    "                        else:\n",
    "                            num_saccade_aoi_subtitle_in2aoi = num_saccade_aoi_subtitle_in2aoi + 1\n",
    "                    \n",
    "                else:\n",
    "                    list_duration_fixation_aoi_out.append(row['GazeEventDuration'])\n",
    "                    if temp_aoi == \"slide\":\n",
    "                        num_saccade_aoi_slide_in2out = num_saccade_aoi_slide_in2out + 1\n",
    "                    elif temp_aoi == \"face\":\n",
    "                        num_saccade_aoi_face_in2out = num_saccade_aoi_face_in2out + 1\n",
    "                    elif temp_aoi == \"subtitle\":\n",
    "                        num_saccade_aoi_subtitle_in2out = num_saccade_aoi_subtitle_in2out + 1\n",
    "                 \n",
    "                temp_aoi = current_aoi\n",
    "        \n",
    "        num_saccade_horizon = sum(1 for i in list_saccadeangel if ((i <= 30 and i >= -30) or (i >= 150 and i <= 210) or (i >= 330)))\n",
    "        print num_saccade_horizon\n",
    "        print len(list_fixationduration)\n",
    "        print len(list_saccadeduration)\n",
    "        print len(list_saccadedistance)\n",
    "        print len(list_saccadeangel)\n",
    "        print len(list_duration_fixation_aoi_face)\n",
    "        print len(list_duration_fixation_aoi_subtitle)\n",
    "        print len(list_duration_fixation_aoi_slide)\n",
    "        print len(list_duration_fixation_aoi_out)\n",
    "        \n",
    "        duration_fixation_aoi_face = 0\n",
    "        duration_fixation_aoi_face_max = 0\n",
    "        duration_fixation_aoi_subtitle = 0\n",
    "        duration_fixation_aoi_subtitle_max = 0\n",
    "        duration_fixation_aoi_slide = 0\n",
    "        duration_fixation_aoi_slide_max = 0\n",
    "        duration_fixation_aoi_out = 0\n",
    "        duration_fixation_aoi_out_max = 0 \n",
    "        \n",
    "        if len(list_duration_fixation_aoi_face) != 0:\n",
    "            duration_fixation_aoi_face = sum(list_duration_fixation_aoi_face)/sum(list_fixationduration)\n",
    "            duration_fixation_aoi_face_max = np.max(list_duration_fixation_aoi_face)\n",
    "        if len(list_duration_fixation_aoi_subtitle) != 0:\n",
    "            duration_fixation_aoi_subtitle = sum(list_duration_fixation_aoi_subtitle)/sum(list_fixationduration)\n",
    "            duration_fixation_aoi_subtitle_max = np.max(list_duration_fixation_aoi_subtitle)\n",
    "        if len(list_duration_fixation_aoi_slide) != 0:\n",
    "            duration_fixation_aoi_slide = sum(list_duration_fixation_aoi_slide)/sum(list_fixationduration)\n",
    "            duration_fixation_aoi_slide_max = np.max(list_duration_fixation_aoi_slide)\n",
    "        if len(list_duration_fixation_aoi_out) != 0:\n",
    "            duration_fixation_aoi_out = sum(list_duration_fixation_aoi_out)/sum(list_fixationduration)\n",
    "            duration_fixation_aoi_out_max = np.max(list_duration_fixation_aoi_out)\n",
    "        \n",
    "        ## Add features into df_features\n",
    "        df_features = df_features.append({\n",
    "                'id': id_str, \n",
    "                'starttime_iso': starttime_iso, \n",
    "                'endtime_iso': endtime_iso,\n",
    "                'fixationduration_min': np.min(list_fixationduration),\n",
    "                'fixationduration_max': np.max(list_fixationduration),\n",
    "                'fixationduration_mean': np.mean(list_fixationduration),\n",
    "                'fixationduration_median': np.median(list_fixationduration),\n",
    "                'fixationduration_stddev': np.std(list_fixationduration),\n",
    "                'fixationduration_range': np.max(list_fixationduration) - np.min(list_fixationduration),\n",
    "                'fixationduration_kurtosis': kurtosis(list_fixationduration),\n",
    "                'fixationduration_skew': skew(list_fixationduration),\n",
    "                'saccadeduration_min': np.min(list_saccadeduration),\n",
    "                'saccadeduration_max': np.max(list_saccadeduration),\n",
    "                'saccadeduration_mean': np.mean(list_saccadeduration),\n",
    "                'saccadeduration_median': np.median(list_saccadeduration),\n",
    "                'saccadeduration_stddev': np.std(list_saccadeduration),\n",
    "                'saccadeduration_range': np.max(list_saccadeduration) - np.min(list_saccadeduration),\n",
    "                'saccadeduration_kurtosis': kurtosis(list_saccadeduration),\n",
    "                'saccadeduration_skew': skew(list_saccadeduration),\n",
    "                'saccadedistance_min': np.min(list_saccadedistance),\n",
    "                'saccadedistance_max': np.max(list_saccadedistance),\n",
    "                'saccadedistance_mean': np.mean(list_saccadedistance),\n",
    "                'saccadedistance_median': np.median(list_saccadedistance),\n",
    "                'saccadedistance_stddev': np.std(list_saccadedistance),\n",
    "                'saccadedistance_range': np.max(list_saccadedistance) - np.min(list_saccadedistance),\n",
    "                'saccadedistance_kurtosis': kurtosis(list_saccadedistance),\n",
    "                'saccadedistance_skew': skew(list_saccadedistance),\n",
    "                'saccadeangel_min': np.min(list_saccadeangel),\n",
    "                'saccadeangel_max': np.max(list_saccadeangel),\n",
    "                'saccadeangel_mean': np.mean(list_saccadeangel),\n",
    "                'saccadeangel_median': np.median(list_saccadeangel),\n",
    "                'saccadeangel_stddev': np.std(list_saccadeangel),\n",
    "                'saccadeangel_range': np.max(list_saccadeangel) - np.min(list_saccadeangel),\n",
    "                'saccadeangel_kurtosis': kurtosis(list_saccadeangel),\n",
    "                'saccadeangel_skew': skew(list_saccadeangel),\n",
    "                'saccade_num': len(list_saccadeduration),\n",
    "                'saccade_horizonratio': num_saccade_horizon/len(list_saccadeangel),\n",
    "                'fixation_saccade_ratio': sum(list_fixationduration)/sum(list_saccadeduration),\n",
    "                ## LOCAL FEATURES\n",
    "                'num_saccade_aoi_face_out2in': num_saccade_aoi_face_out2in/len(list_saccadeduration),\n",
    "                'num_saccade_aoi_face_aoi2in': num_saccade_aoi_face_aoi2in/len(list_saccadeduration),\n",
    "                'num_saccade_aoi_face_in2out': num_saccade_aoi_face_in2out/len(list_saccadeduration),\n",
    "                'num_saccade_aoi_face_in2aoi': num_saccade_aoi_face_in2aoi/len(list_saccadeduration),\n",
    "                'num_saccade_aoi_face_within': num_saccade_aoi_face_within/len(list_saccadeduration),\n",
    "                'num_saccade_aoi_slide_out2in': num_saccade_aoi_slide_out2in/len(list_saccadeduration),\n",
    "                'num_saccade_aoi_slide_aoi2in': num_saccade_aoi_slide_aoi2in/len(list_saccadeduration),\n",
    "                'num_saccade_aoi_slide_in2out': num_saccade_aoi_slide_in2out/len(list_saccadeduration),\n",
    "                'num_saccade_aoi_slide_in2aoi': num_saccade_aoi_slide_in2aoi/len(list_saccadeduration),\n",
    "                'num_saccade_aoi_slide_within': num_saccade_aoi_slide_within/len(list_saccadeduration),\n",
    "                'num_saccade_aoi_subtitle_out2in': num_saccade_aoi_subtitle_out2in/len(list_saccadeduration),\n",
    "                'num_saccade_aoi_subtitle_aoi2in': num_saccade_aoi_subtitle_aoi2in/len(list_saccadeduration),\n",
    "                'num_saccade_aoi_subtitle_in2out': num_saccade_aoi_subtitle_in2out/len(list_saccadeduration),\n",
    "                'num_saccade_aoi_subtitle_in2aoi': num_saccade_aoi_subtitle_in2aoi/len(list_saccadeduration),\n",
    "                'num_saccade_aoi_subtitle_within': num_saccade_aoi_subtitle_within/len(list_saccadeduration),\n",
    "                'duration_fixation_aoi_face': duration_fixation_aoi_face,\n",
    "                'duration_fixation_aoi_face_max': duration_fixation_aoi_face_max,\n",
    "                'duration_fixation_aoi_subtitle': duration_fixation_aoi_subtitle,\n",
    "                'duration_fixation_aoi_subtitle_max': duration_fixation_aoi_subtitle_max,\n",
    "                'duration_fixation_aoi_slide': duration_fixation_aoi_slide,\n",
    "                'duration_fixation_aoi_slide_max': duration_fixation_aoi_slide_max,\n",
    "                'duration_fixation_aoi_out': duration_fixation_aoi_out,\n",
    "                'duration_fixation_aoi_out_max': duration_fixation_aoi_out_max\n",
    "            }, ignore_index=True)\n",
    "        \n",
    "        # print df_features.head(1)\n",
    "print df_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Merge features with labels\n",
    "df_merge = pd.merge(df_reports, df_features)\n",
    "df_merge.to_csv(\"features_labels_webgazer.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'endtime_iso', u'endtime_video', u'fullscreen', u'id', u'label',\n",
      "       u'starttime_iso', u'starttime_video', u'video_id', u'video_length',\n",
      "       u'video_order', u'duration_fixation_aoi_face',\n",
      "       u'duration_fixation_aoi_face_max', u'duration_fixation_aoi_out',\n",
      "       u'duration_fixation_aoi_out_max', u'duration_fixation_aoi_slide',\n",
      "       u'duration_fixation_aoi_slide_max', u'duration_fixation_aoi_subtitle',\n",
      "       u'duration_fixation_aoi_subtitle_max', u'fixation_saccade_ratio',\n",
      "       u'fixationduration_kurtosis', u'fixationduration_max',\n",
      "       u'fixationduration_mean', u'fixationduration_median',\n",
      "       u'fixationduration_min', u'fixationduration_range',\n",
      "       u'fixationduration_skew', u'fixationduration_stddev',\n",
      "       u'num_saccade_aoi_face_aoi2in', u'num_saccade_aoi_face_in2aoi',\n",
      "       u'num_saccade_aoi_face_in2out', u'num_saccade_aoi_face_out2in',\n",
      "       u'num_saccade_aoi_face_within', u'num_saccade_aoi_slide_aoi2in',\n",
      "       u'num_saccade_aoi_slide_in2aoi', u'num_saccade_aoi_slide_in2out',\n",
      "       u'num_saccade_aoi_slide_out2in', u'num_saccade_aoi_slide_within',\n",
      "       u'num_saccade_aoi_subtitle_aoi2in', u'num_saccade_aoi_subtitle_in2aoi',\n",
      "       u'num_saccade_aoi_subtitle_in2out', u'num_saccade_aoi_subtitle_out2in',\n",
      "       u'num_saccade_aoi_subtitle_within', u'saccade_horizonratio',\n",
      "       u'saccade_num', u'saccadeangel_kurtosis', u'saccadeangel_max',\n",
      "       u'saccadeangel_mean', u'saccadeangel_median', u'saccadeangel_min',\n",
      "       u'saccadeangel_range', u'saccadeangel_skew', u'saccadeangel_stddev',\n",
      "       u'saccadedistance_kurtosis', u'saccadedistance_max',\n",
      "       u'saccadedistance_mean', u'saccadedistance_median',\n",
      "       u'saccadedistance_min', u'saccadedistance_range',\n",
      "       u'saccadedistance_skew', u'saccadedistance_stddev',\n",
      "       u'saccadeduration_kurtosis', u'saccadeduration_max',\n",
      "       u'saccadeduration_mean', u'saccadeduration_median',\n",
      "       u'saccadeduration_min', u'saccadeduration_range',\n",
      "       u'saccadeduration_skew', u'saccadeduration_stddev'],\n",
      "      dtype='object')\n",
      "Index([u'duration_fixation_aoi_face', u'duration_fixation_aoi_face_max',\n",
      "       u'duration_fixation_aoi_out', u'duration_fixation_aoi_out_max',\n",
      "       u'duration_fixation_aoi_slide', u'duration_fixation_aoi_slide_max',\n",
      "       u'duration_fixation_aoi_subtitle',\n",
      "       u'duration_fixation_aoi_subtitle_max'],\n",
      "      dtype='object')\n",
      "Index([u'fixation_saccade_ratio', u'fixationduration_kurtosis',\n",
      "       u'fixationduration_max', u'fixationduration_mean',\n",
      "       u'fixationduration_median', u'fixationduration_min',\n",
      "       u'fixationduration_range', u'fixationduration_skew',\n",
      "       u'fixationduration_stddev'],\n",
      "      dtype='object')\n",
      "Index([u'num_saccade_aoi_face_aoi2in', u'num_saccade_aoi_face_in2aoi',\n",
      "       u'num_saccade_aoi_face_in2out', u'num_saccade_aoi_face_out2in',\n",
      "       u'num_saccade_aoi_face_within', u'num_saccade_aoi_slide_aoi2in',\n",
      "       u'num_saccade_aoi_slide_in2aoi', u'num_saccade_aoi_slide_in2out',\n",
      "       u'num_saccade_aoi_slide_out2in', u'num_saccade_aoi_slide_within',\n",
      "       u'num_saccade_aoi_subtitle_aoi2in', u'num_saccade_aoi_subtitle_in2aoi',\n",
      "       u'num_saccade_aoi_subtitle_in2out', u'num_saccade_aoi_subtitle_out2in',\n",
      "       u'num_saccade_aoi_subtitle_within'],\n",
      "      dtype='object')\n",
      "Index([u'saccade_horizonratio', u'saccade_num', u'saccadeangel_kurtosis',\n",
      "       u'saccadeangel_max', u'saccadeangel_mean', u'saccadeangel_median',\n",
      "       u'saccadeangel_min', u'saccadeangel_range', u'saccadeangel_skew',\n",
      "       u'saccadeangel_stddev', u'saccadedistance_kurtosis',\n",
      "       u'saccadedistance_max', u'saccadedistance_mean',\n",
      "       u'saccadedistance_median', u'saccadedistance_min',\n",
      "       u'saccadedistance_range', u'saccadedistance_skew',\n",
      "       u'saccadedistance_stddev', u'saccadeduration_kurtosis',\n",
      "       u'saccadeduration_max', u'saccadeduration_mean',\n",
      "       u'saccadeduration_median', u'saccadeduration_min',\n",
      "       u'saccadeduration_range', u'saccadeduration_skew',\n",
      "       u'saccadeduration_stddev'],\n",
      "      dtype='object')\n",
      "68\n"
     ]
    }
   ],
   "source": [
    "print df_merge.columns\n",
    "print df_merge.columns[10:18]\n",
    "print df_merge.columns[18:27]\n",
    "print df_merge.columns[27:42]\n",
    "print df_merge.columns[42:]\n",
    "print len(df_merge.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the results of the baseline\n",
    "Assumin that we know the mind-wandering rate is 0.29, the baseline is the precision, recall and f1 when we totally guess the result with 0.29 mind-wandering rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 68)\n",
      "Baseline with 0.29 mind-wandering rate\n",
      "\tPrecision: 0.290\n",
      "\tRecall: 0.291\n",
      "\tF1: 0.290\n",
      "\tAccuracy: 0.588\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from random import random, seed\n",
    "from sklearn.metrics import (precision_score, recall_score, f1_score, accuracy_score)\n",
    "\n",
    "# read the data\n",
    "df_merge = pd.read_csv(\"features_labels_webgazer.csv\")\n",
    "# read the label\n",
    "y_test = df_merge.ix[:, 4]\n",
    "print df_merge.shape\n",
    "\n",
    "repeat_parameter = 10000\n",
    "seed_parameter = 48 # same as the example in SMOTE\n",
    "\n",
    "list_test = list()\n",
    "for i in range(0, repeat_parameter):\n",
    "    list_test = list_test + list(y_test)\n",
    "\n",
    "seed(seed_parameter)\n",
    "list_guess = list()\n",
    "for i in range(0, len(list_test)):\n",
    "    temp_random = random()\n",
    "    if temp_random > 0.29:\n",
    "        list_guess.append(0)\n",
    "    else:\n",
    "        list_guess.append(1)\n",
    "\n",
    "print \"Baseline with 0.29 mind-wandering rate\"\n",
    "print(\"\\tPrecision: %1.3f\" % precision_score(list_test, list_guess))\n",
    "print(\"\\tRecall: %1.3f\" % recall_score(list_test, list_guess))\n",
    "print(\"\\tF1: %1.3f\" % f1_score(list_test, list_guess))\n",
    "print(\"\\tAccuracy: %1.3f\\n\" % accuracy_score(list_test, list_guess))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction With Global Features and Local Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 Logistic Regression\n",
      "\tPrecision: 0.238\n",
      "\tRecall: 0.086\n",
      "\tF1: 0.127\n",
      "\tAccuracy: 0.655\n",
      "\n",
      "L2 Logistic Regression\n",
      "\tPrecision: 0.111\n",
      "\tRecall: 0.017\n",
      "\tF1: 0.030\n",
      "\tAccuracy: 0.675\n",
      "\n",
      "SVC\n",
      "\tPrecision: 0.000\n",
      "\tRecall: 0.000\n",
      "\tF1: 0.000\n",
      "\tAccuracy: 0.710\n",
      "\n",
      "Decision Tree\n",
      "\tPrecision: 0.290\n",
      "\tRecall: 0.345\n",
      "\tF1: 0.315\n",
      "\tAccuracy: 0.565\n",
      "\n",
      "Gaussian Naive Bayes\n",
      "\tPrecision: 0.352\n",
      "\tRecall: 0.776\n",
      "\tF1: 0.484\n",
      "\tAccuracy: 0.520\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.metrics import (precision_score, recall_score, f1_score, accuracy_score)\n",
    "## Read data from features_labels_tobii.csv\n",
    "\n",
    "df_merge = pd.read_csv(\"features_labels_webgazer.csv\")\n",
    "# df_merge = pd.read_csv(\"features_labels_tobii_2.csv\")\n",
    "list_id_report = list(df_merge['id'].unique())\n",
    "\n",
    "y_test_total = []\n",
    "y_pred_l1_total = []\n",
    "y_pred_l2_total = []\n",
    "y_pred_svc_total = []\n",
    "y_pred_tree_total = []\n",
    "y_pred_bayes_total = []\n",
    "y_pred_rf_total = []\n",
    "\n",
    "## Leave-one-out machine learning methods (try Logistic Regression first)\n",
    "for i in range(0, len(list_id_report)):\n",
    "    id_str = list_id_report[i]\n",
    "    \n",
    "    # print id_str\n",
    "    # print \"Run: \" + str(i)\n",
    "    data_train = df_merge.ix[df_merge['id'] != id_str]\n",
    "    # print data_train.shape\n",
    "    data_test = df_merge.ix[df_merge['id'] == id_str]\n",
    "    # print data_test.shape\n",
    "    \n",
    "    X_train = data_train.ix[:, 10:].fillna(value=0)\n",
    "    y_train = data_train.ix[:, 4]\n",
    "    \n",
    "#     sm = SMOTE(random_state=48)\n",
    "#     X_train, y_train = sm.fit_sample(X_train, y_train)\n",
    "    \n",
    "    X_test = data_test.ix[:, 10:].fillna(value=0)\n",
    "    y_test = data_test.ix[:, 4]\n",
    "    \n",
    "    y_test_total.extend(y_test)\n",
    "    \n",
    "    ## Logistic Regression\n",
    "    clf_l1_LR = LogisticRegression(penalty='l1', tol=0.01)\n",
    "    clf_l1_LR = clf_l1_LR.fit(X_train, y_train)\n",
    "    y_pred_l1 = clf_l1_LR.predict(X_test)\n",
    "    y_pred_l1_total.extend(y_pred_l1)\n",
    "    \n",
    "    clf_l2_LR = LogisticRegression(penalty='l2', tol=0.01)\n",
    "    clf_l2_LR = clf_l2_LR.fit(X_train, y_train)\n",
    "    y_pred_l2 = clf_l2_LR.predict(X_test)\n",
    "    y_pred_l2_total.extend(y_pred_l2)\n",
    "        \n",
    "    ## SVM with unbalanced class weight\n",
    "    clf_SVC = SVC(class_weight = {0:1, 1:3})\n",
    "    clf_SVC = clf_SVC.fit(X_train, y_train)\n",
    "    y_pred_svc = clf_SVC.predict(X_test)\n",
    "    y_pred_svc_total.extend(y_pred_svc)\n",
    "    \n",
    "    ## Decision tree\n",
    "    clf_tree = DecisionTreeClassifier()\n",
    "    clf_tree = clf_tree.fit(X_train, y_train)\n",
    "    y_pred_tree = clf_tree.predict(X_test)\n",
    "    y_pred_tree_total.extend(y_pred_tree)\n",
    "    \n",
    "    \n",
    "    ## GaussianNB\n",
    "    clf_GaussianNB = GaussianNB()\n",
    "    clf_GaussianNB = clf_GaussianNB.fit(X_train, y_train)\n",
    "    y_pred_bayes = clf_GaussianNB.predict(X_test)\n",
    "    y_pred_bayes_total.extend(y_pred_bayes)\n",
    "    \n",
    "#     ## Random Forest\n",
    "#     clf_rf = RandomForestClassifier()\n",
    "#     clf_rf = clf_rf.fit(X_train, y_train)\n",
    "#     y_pred_rf = clf_rf.predict(X_test)\n",
    "#     y_pred_rf_total.extend(y_pred_rf)\n",
    "    \n",
    "\n",
    "print \"L1 Logistic Regression\"\n",
    "print(\"\\tPrecision: %1.3f\" % precision_score(y_test_total, y_pred_l1_total))\n",
    "print(\"\\tRecall: %1.3f\" % recall_score(y_test_total, y_pred_l1_total))\n",
    "print(\"\\tF1: %1.3f\" % f1_score(y_test_total, y_pred_l1_total))\n",
    "print(\"\\tAccuracy: %1.3f\\n\" % accuracy_score(y_test_total, y_pred_l1_total))\n",
    "\n",
    "print \"L2 Logistic Regression\"\n",
    "print(\"\\tPrecision: %1.3f\" % precision_score(y_test_total, y_pred_l2_total))\n",
    "print(\"\\tRecall: %1.3f\" % recall_score(y_test_total, y_pred_l2_total))\n",
    "print(\"\\tF1: %1.3f\" % f1_score(y_test_total, y_pred_l2_total))\n",
    "print(\"\\tAccuracy: %1.3f\\n\" % accuracy_score(y_test_total, y_pred_l2_total))\n",
    "\n",
    "print \"SVC\"\n",
    "print(\"\\tPrecision: %1.3f\" % precision_score(y_test_total, y_pred_svc_total))\n",
    "print(\"\\tRecall: %1.3f\" % recall_score(y_test_total, y_pred_svc_total))\n",
    "print(\"\\tF1: %1.3f\" % f1_score(y_test_total, y_pred_svc_total))\n",
    "print(\"\\tAccuracy: %1.3f\\n\" % accuracy_score(y_test_total, y_pred_svc_total))\n",
    "\n",
    "print \"Decision Tree\"\n",
    "print(\"\\tPrecision: %1.3f\" % precision_score(y_test_total, y_pred_tree_total))\n",
    "print(\"\\tRecall: %1.3f\" % recall_score(y_test_total, y_pred_tree_total))\n",
    "print(\"\\tF1: %1.3f\" % f1_score(y_test_total, y_pred_tree_total))\n",
    "print(\"\\tAccuracy: %1.3f\\n\" % accuracy_score(y_test_total, y_pred_tree_total))\n",
    "\n",
    "print \"Gaussian Naive Bayes\"\n",
    "print(\"\\tPrecision: %1.3f\" % precision_score(y_test_total, y_pred_bayes_total))\n",
    "print(\"\\tRecall: %1.3f\" % recall_score(y_test_total, y_pred_bayes_total))\n",
    "print(\"\\tF1: %1.3f\" % f1_score(y_test_total, y_pred_bayes_total))\n",
    "print(\"\\tAccuracy: %1.3f\\n\" % accuracy_score(y_test_total, y_pred_bayes_total))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction With Local Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 Logistic Regression\n",
      "\tPrecision: 0.000\n",
      "\tRecall: 0.000\n",
      "\tF1: 0.000\n",
      "\tAccuracy: 0.710\n",
      "\n",
      "L2 Logistic Regression\n",
      "\tPrecision: 0.000\n",
      "\tRecall: 0.000\n",
      "\tF1: 0.000\n",
      "\tAccuracy: 0.710\n",
      "\n",
      "SVC\n",
      "\tPrecision: 0.000\n",
      "\tRecall: 0.000\n",
      "\tF1: 0.000\n",
      "\tAccuracy: 0.710\n",
      "\n",
      "Decision Tree\n",
      "\tPrecision: 0.324\n",
      "\tRecall: 0.397\n",
      "\tF1: 0.357\n",
      "\tAccuracy: 0.585\n",
      "\n",
      "Gaussian Naive Bayes\n",
      "\tPrecision: 0.342\n",
      "\tRecall: 0.690\n",
      "\tF1: 0.457\n",
      "\tAccuracy: 0.525\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.metrics import (precision_score, recall_score, f1_score, accuracy_score)\n",
    "## Read data from features_labels_tobii.csv\n",
    "\n",
    "df_merge = pd.read_csv(\"features_labels_webgazer.csv\")\n",
    "list_id_report = list(df_merge['id'].unique())\n",
    "\n",
    "y_test_total = []\n",
    "y_pred_l1_total = []\n",
    "y_pred_l2_total = []\n",
    "y_pred_svc_total = []\n",
    "y_pred_tree_total = []\n",
    "y_pred_bayes_total = []\n",
    "y_pred_rf_total = []\n",
    "\n",
    "## Leave-one-out machine learning methods (try Logistic Regression first)\n",
    "for i in range(0, len(list_id_report)):\n",
    "    id_str = list_id_report[i]\n",
    "    \n",
    "    # print id_str\n",
    "    # print \"Run: \" + str(i)\n",
    "    data_train = df_merge.ix[df_merge['id'] != id_str]\n",
    "    # print data_train.shape\n",
    "    data_test = df_merge.ix[df_merge['id'] == id_str]\n",
    "    # print data_test.shape\n",
    "    feature_index_local = [10,11,12,13,14,15,16,17,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41]\n",
    "    X_train = data_train.ix[:, feature_index_local].fillna(value=0)\n",
    "    y_train = data_train.ix[:, 4]\n",
    "    \n",
    "#     sm = SMOTE(random_state=48)\n",
    "#     X_train, y_train = sm.fit_sample(X_train, y_train)\n",
    "    \n",
    "    X_test = data_test.ix[:, feature_index_local].fillna(value=0)\n",
    "    y_test = data_test.ix[:, 4]\n",
    "    \n",
    "    y_test_total.extend(y_test)\n",
    "    \n",
    "    ## Logistic Regression\n",
    "    # for i, C in enumerate((100, 1, 0.01)):\n",
    "    # turn down tolerance for short training time\n",
    "    clf_l1_LR = LogisticRegression(penalty='l1', tol=0.01)\n",
    "    clf_l1_LR = clf_l1_LR.fit(X_train, y_train)\n",
    "    y_pred_l1 = clf_l1_LR.predict(X_test)\n",
    "    y_pred_l1_total.extend(y_pred_l1)\n",
    "    \n",
    "    clf_l2_LR = LogisticRegression(penalty='l2', tol=0.01)\n",
    "    clf_l2_LR = clf_l2_LR.fit(X_train, y_train)\n",
    "    y_pred_l2 = clf_l2_LR.predict(X_test)\n",
    "    y_pred_l2_total.extend(y_pred_l2)\n",
    "        \n",
    "    ## SVM with unbalanced class weight\n",
    "    clf_SVC = SVC(class_weight = {0:1, 1:3})\n",
    "    clf_SVC = clf_SVC.fit(X_train, y_train)\n",
    "    y_pred_svc = clf_SVC.predict(X_test)\n",
    "    y_pred_svc_total.extend(y_pred_svc)\n",
    "    \n",
    "    ## Decision tree\n",
    "    clf_tree = DecisionTreeClassifier()\n",
    "    clf_tree = clf_tree.fit(X_train, y_train)\n",
    "    y_pred_tree = clf_tree.predict(X_test)\n",
    "    y_pred_tree_total.extend(y_pred_tree)\n",
    "    \n",
    "    \n",
    "    ## GaussianNB\n",
    "    clf_GaussianNB = GaussianNB()\n",
    "    clf_GaussianNB = clf_GaussianNB.fit(X_train, y_train)\n",
    "    y_pred_bayes = clf_GaussianNB.predict(X_test)\n",
    "    y_pred_bayes_total.extend(y_pred_bayes)\n",
    "    \n",
    "\n",
    "print \"L1 Logistic Regression\"\n",
    "print(\"\\tPrecision: %1.3f\" % precision_score(y_test_total, y_pred_l1_total))\n",
    "print(\"\\tRecall: %1.3f\" % recall_score(y_test_total, y_pred_l1_total))\n",
    "print(\"\\tF1: %1.3f\" % f1_score(y_test_total, y_pred_l1_total))\n",
    "print(\"\\tAccuracy: %1.3f\\n\" % accuracy_score(y_test_total, y_pred_l1_total))\n",
    "\n",
    "print \"L2 Logistic Regression\"\n",
    "print(\"\\tPrecision: %1.3f\" % precision_score(y_test_total, y_pred_l2_total))\n",
    "print(\"\\tRecall: %1.3f\" % recall_score(y_test_total, y_pred_l2_total))\n",
    "print(\"\\tF1: %1.3f\" % f1_score(y_test_total, y_pred_l2_total))\n",
    "print(\"\\tAccuracy: %1.3f\\n\" % accuracy_score(y_test_total, y_pred_l2_total))\n",
    "\n",
    "print \"SVC\"\n",
    "print(\"\\tPrecision: %1.3f\" % precision_score(y_test_total, y_pred_svc_total))\n",
    "print(\"\\tRecall: %1.3f\" % recall_score(y_test_total, y_pred_svc_total))\n",
    "print(\"\\tF1: %1.3f\" % f1_score(y_test_total, y_pred_svc_total))\n",
    "print(\"\\tAccuracy: %1.3f\\n\" % accuracy_score(y_test_total, y_pred_svc_total))\n",
    "\n",
    "print \"Decision Tree\"\n",
    "print(\"\\tPrecision: %1.3f\" % precision_score(y_test_total, y_pred_tree_total))\n",
    "print(\"\\tRecall: %1.3f\" % recall_score(y_test_total, y_pred_tree_total))\n",
    "print(\"\\tF1: %1.3f\" % f1_score(y_test_total, y_pred_tree_total))\n",
    "print(\"\\tAccuracy: %1.3f\\n\" % accuracy_score(y_test_total, y_pred_tree_total))\n",
    "\n",
    "print \"Gaussian Naive Bayes\"\n",
    "print(\"\\tPrecision: %1.3f\" % precision_score(y_test_total, y_pred_bayes_total))\n",
    "print(\"\\tRecall: %1.3f\" % recall_score(y_test_total, y_pred_bayes_total))\n",
    "print(\"\\tF1: %1.3f\" % f1_score(y_test_total, y_pred_bayes_total))\n",
    "print(\"\\tAccuracy: %1.3f\\n\" % accuracy_score(y_test_total, y_pred_bayes_total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction With Global Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 Logistic Regression\n",
      "\tPrecision: 0.077\n",
      "\tRecall: 0.017\n",
      "\tF1: 0.028\n",
      "\tAccuracy: 0.655\n",
      "\n",
      "L2 Logistic Regression\n",
      "\tPrecision: 0.154\n",
      "\tRecall: 0.034\n",
      "\tF1: 0.056\n",
      "\tAccuracy: 0.665\n",
      "\n",
      "SVC\n",
      "\tPrecision: 0.000\n",
      "\tRecall: 0.000\n",
      "\tF1: 0.000\n",
      "\tAccuracy: 0.710\n",
      "\n",
      "Decision Tree\n",
      "\tPrecision: 0.232\n",
      "\tRecall: 0.276\n",
      "\tF1: 0.252\n",
      "\tAccuracy: 0.525\n",
      "\n",
      "Gaussian Naive Bayes\n",
      "\tPrecision: 0.339\n",
      "\tRecall: 0.690\n",
      "\tF1: 0.455\n",
      "\tAccuracy: 0.520\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.metrics import (precision_score, recall_score, f1_score, accuracy_score)\n",
    "## Read data from features_labels_tobii.csv\n",
    "\n",
    "df_merge = pd.read_csv(\"features_labels_webgazer.csv\")\n",
    "list_id_report = list(df_merge['id'].unique())\n",
    "\n",
    "y_test_total = []\n",
    "y_pred_l1_total = []\n",
    "y_pred_l2_total = []\n",
    "y_pred_svc_total = []\n",
    "y_pred_tree_total = []\n",
    "y_pred_bayes_total = []\n",
    "y_pred_rf_total = []\n",
    "\n",
    "## Leave-one-out machine learning methods (try Logistic Regression first)\n",
    "for i in range(0, len(list_id_report)):\n",
    "    id_str = list_id_report[i]\n",
    "    \n",
    "    # print id_str\n",
    "    # print \"Run: \" + str(i)\n",
    "    data_train = df_merge.ix[df_merge['id'] != id_str]\n",
    "    # print data_train.shape\n",
    "    data_test = df_merge.ix[df_merge['id'] == id_str]\n",
    "    # print data_test.shape\n",
    "    feature_index_global = [18,19,20,21,22,23,24,25,26,\n",
    "                            42,43,44,45,46,47,48,49,50,\n",
    "                            51,52,53,54,55,56,57,58,59,\n",
    "                            60,61,62,63,64,65,66,67]\n",
    "    X_train = data_train.ix[:, feature_index_global].fillna(value=0)\n",
    "    y_train = data_train.ix[:, 4]\n",
    "    \n",
    "#     sm = SMOTE(random_state=48)\n",
    "#     X_train, y_train = sm.fit_sample(X_train, y_train)\n",
    "    \n",
    "    X_test = data_test.ix[:, feature_index_global].fillna(value=0)\n",
    "    y_test = data_test.ix[:, 4]\n",
    "    \n",
    "    y_test_total.extend(y_test)\n",
    "    \n",
    "    ## Logistic Regression\n",
    "    clf_l1_LR = LogisticRegression(penalty='l1', tol=0.01)\n",
    "    clf_l1_LR = clf_l1_LR.fit(X_train, y_train)\n",
    "    y_pred_l1 = clf_l1_LR.predict(X_test)\n",
    "    y_pred_l1_total.extend(y_pred_l1)\n",
    "    \n",
    "    clf_l2_LR = LogisticRegression(penalty='l2', tol=0.01)\n",
    "    clf_l2_LR = clf_l2_LR.fit(X_train, y_train)\n",
    "    y_pred_l2 = clf_l2_LR.predict(X_test)\n",
    "    y_pred_l2_total.extend(y_pred_l2)\n",
    "        \n",
    "    ## SVM with unbalanced class weight\n",
    "    clf_SVC = SVC(class_weight = {0:1, 1:3})\n",
    "    clf_SVC = clf_SVC.fit(X_train, y_train)\n",
    "    y_pred_svc = clf_SVC.predict(X_test)\n",
    "    y_pred_svc_total.extend(y_pred_svc)\n",
    "    \n",
    "    ## Decision tree\n",
    "    clf_tree = DecisionTreeClassifier()\n",
    "    clf_tree = clf_tree.fit(X_train, y_train)\n",
    "    y_pred_tree = clf_tree.predict(X_test)\n",
    "    y_pred_tree_total.extend(y_pred_tree)\n",
    "    \n",
    "    \n",
    "    ## GaussianNB\n",
    "    clf_GaussianNB = GaussianNB()\n",
    "    clf_GaussianNB = clf_GaussianNB.fit(X_train, y_train)\n",
    "    y_pred_bayes = clf_GaussianNB.predict(X_test)\n",
    "    y_pred_bayes_total.extend(y_pred_bayes)\n",
    "    \n",
    "#     ## Random Forest\n",
    "#     clf_rf = RandomForestClassifier()\n",
    "#     clf_rf = clf_rf.fit(X_train, y_train)\n",
    "#     y_pred_rf = clf_rf.predict(X_test)\n",
    "#     y_pred_rf_total.extend(y_pred_rf)\n",
    "    \n",
    "\n",
    "print \"L1 Logistic Regression\"\n",
    "print(\"\\tPrecision: %1.3f\" % precision_score(y_test_total, y_pred_l1_total))\n",
    "print(\"\\tRecall: %1.3f\" % recall_score(y_test_total, y_pred_l1_total))\n",
    "print(\"\\tF1: %1.3f\" % f1_score(y_test_total, y_pred_l1_total))\n",
    "print(\"\\tAccuracy: %1.3f\\n\" % accuracy_score(y_test_total, y_pred_l1_total))\n",
    "\n",
    "print \"L2 Logistic Regression\"\n",
    "print(\"\\tPrecision: %1.3f\" % precision_score(y_test_total, y_pred_l2_total))\n",
    "print(\"\\tRecall: %1.3f\" % recall_score(y_test_total, y_pred_l2_total))\n",
    "print(\"\\tF1: %1.3f\" % f1_score(y_test_total, y_pred_l2_total))\n",
    "print(\"\\tAccuracy: %1.3f\\n\" % accuracy_score(y_test_total, y_pred_l2_total))\n",
    "\n",
    "print \"SVC\"\n",
    "print(\"\\tPrecision: %1.3f\" % precision_score(y_test_total, y_pred_svc_total))\n",
    "print(\"\\tRecall: %1.3f\" % recall_score(y_test_total, y_pred_svc_total))\n",
    "print(\"\\tF1: %1.3f\" % f1_score(y_test_total, y_pred_svc_total))\n",
    "print(\"\\tAccuracy: %1.3f\\n\" % accuracy_score(y_test_total, y_pred_svc_total))\n",
    "\n",
    "print \"Decision Tree\"\n",
    "print(\"\\tPrecision: %1.3f\" % precision_score(y_test_total, y_pred_tree_total))\n",
    "print(\"\\tRecall: %1.3f\" % recall_score(y_test_total, y_pred_tree_total))\n",
    "print(\"\\tF1: %1.3f\" % f1_score(y_test_total, y_pred_tree_total))\n",
    "print(\"\\tAccuracy: %1.3f\\n\" % accuracy_score(y_test_total, y_pred_tree_total))\n",
    "\n",
    "print \"Gaussian Naive Bayes\"\n",
    "print(\"\\tPrecision: %1.3f\" % precision_score(y_test_total, y_pred_bayes_total))\n",
    "print(\"\\tRecall: %1.3f\" % recall_score(y_test_total, y_pred_bayes_total))\n",
    "print(\"\\tF1: %1.3f\" % f1_score(y_test_total, y_pred_bayes_total))\n",
    "print(\"\\tAccuracy: %1.3f\\n\" % accuracy_score(y_test_total, y_pred_bayes_total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Whether or not predictions can be made equally well for all participants?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anon01\n",
      "Run: 0\n",
      "\tPrecision: 0.500\n",
      "\tRecall: 0.400\n",
      "\tF1: 0.444\n",
      "\tAccuracy: 0.688\n",
      "\n",
      "Anon02\n",
      "Run: 1\n",
      "\tPrecision: 0.667\n",
      "\tRecall: 0.571\n",
      "\tF1: 0.615\n",
      "\tAccuracy: 0.706\n",
      "\n",
      "Anon03\n",
      "Run: 2\n",
      "\tPrecision: 0.400\n",
      "\tRecall: 0.667\n",
      "\tF1: 0.500\n",
      "\tAccuracy: 0.467\n",
      "\n",
      "Anon04\n",
      "Run: 3\n",
      "\tPrecision: 0.333\n",
      "\tRecall: 0.750\n",
      "\tF1: 0.462\n",
      "\tAccuracy: 0.533\n",
      "\n",
      "Anon05\n",
      "Run: 4\n",
      "\tPrecision: 0.364\n",
      "\tRecall: 1.000\n",
      "\tF1: 0.533\n",
      "\tAccuracy: 0.533\n",
      "\n",
      "Anon06\n",
      "Run: 5\n",
      "\tPrecision: 0.000\n",
      "\tRecall: 0.000\n",
      "\tF1: 0.000\n",
      "\tAccuracy: 0.800\n",
      "\n",
      "Anon07\n",
      "Run: 6\n",
      "\tPrecision: 0.125\n",
      "\tRecall: 1.000\n",
      "\tF1: 0.222\n",
      "\tAccuracy: 0.500\n",
      "\n",
      "Anon08\n",
      "Run: 7\n",
      "\tPrecision: 0.154\n",
      "\tRecall: 1.000\n",
      "\tF1: 0.267\n",
      "\tAccuracy: 0.267\n",
      "\n",
      "Anon09\n",
      "Run: 8\n",
      "\tPrecision: 0.545\n",
      "\tRecall: 0.667\n",
      "\tF1: 0.600\n",
      "\tAccuracy: 0.500\n",
      "\n",
      "Anon10\n",
      "Run: 9\n",
      "\tPrecision: 0.357\n",
      "\tRecall: 1.000\n",
      "\tF1: 0.526\n",
      "\tAccuracy: 0.438\n",
      "\n",
      "Anon11\n",
      "Run: 10\n",
      "\tPrecision: 0.600\n",
      "\tRecall: 1.000\n",
      "\tF1: 0.750\n",
      "\tAccuracy: 0.625\n",
      "\n",
      "Anon12\n",
      "Run: 11\n",
      "\tPrecision: 0.308\n",
      "\tRecall: 1.000\n",
      "\tF1: 0.471\n",
      "\tAccuracy: 0.400\n",
      "\n",
      "Anon13\n",
      "Run: 12\n",
      "\tPrecision: 0.083\n",
      "\tRecall: 1.000\n",
      "\tF1: 0.154\n",
      "\tAccuracy: 0.267\n",
      "\n",
      "Final Results: L2 Logistic Regression\n",
      "\tPrecision: 0.352\n",
      "\tRecall: 0.776\n",
      "\tF1: 0.484\n",
      "\tAccuracy: 0.520\n",
      "\n",
      "Precision\n",
      "0.666666666667\n",
      "0.0\n",
      "0.341238889316\n",
      "0.357142857143\n",
      "0.198067499612\n",
      "Recall\n",
      "1.0\n",
      "0.0\n",
      "0.773443223443\n",
      "1.0\n",
      "0.298860919874\n",
      "F1\n",
      "0.75\n",
      "0.0\n",
      "0.426487686323\n",
      "0.470588235294\n",
      "0.200810404845\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.metrics import (precision_score, recall_score, f1_score, accuracy_score)\n",
    "## Read data from features_labels_tobii.csv\n",
    "\n",
    "df_merge = pd.read_csv(\"features_labels_webgazer.csv\")\n",
    "list_id_report = list(df_merge['id'].unique())\n",
    "\n",
    "y_test_total = []\n",
    "y_pred_bayes_total = []\n",
    "\n",
    "list_pre = []\n",
    "list_rec = []\n",
    "list_f1 = []\n",
    "\n",
    "## Leave-one-out machine learning methods (try Logistic Regression first)\n",
    "for i in range(0, len(list_id_report)):\n",
    "    id_str = list_id_report[i]\n",
    "    \n",
    "    print id_str\n",
    "    print \"Run: \" + str(i)\n",
    "    data_train = df_merge.ix[df_merge['id'] != id_str]\n",
    "    # print data_train.shape\n",
    "    data_test = df_merge.ix[df_merge['id'] == id_str]\n",
    "    # print data_test.shape\n",
    "    \n",
    "    X_train = data_train.ix[:, 10:].fillna(value=0)\n",
    "    y_train = data_train.ix[:, 4]\n",
    "    \n",
    "#     sm = SMOTE(random_state=48)\n",
    "#     X_train, y_train = sm.fit_sample(X_train, y_train)\n",
    "    \n",
    "    X_test = data_test.ix[:, 10:].fillna(value=0)\n",
    "    y_test = data_test.ix[:, 4]\n",
    "    \n",
    "    y_test_total.extend(y_test)\n",
    "    \n",
    "    ## Logistic Regression\n",
    "    \n",
    "    clf_GaussianNB = GaussianNB()\n",
    "    clf_GaussianNB = clf_GaussianNB.fit(X_train, y_train)\n",
    "    y_pred_bayes = clf_GaussianNB.predict(X_test)\n",
    "    y_pred_bayes_total.extend(y_pred_bayes)\n",
    "    \n",
    "    print(\"\\tPrecision: %1.3f\" % precision_score(y_test, y_pred_bayes))\n",
    "    print(\"\\tRecall: %1.3f\" % recall_score(y_test, y_pred_bayes))\n",
    "    print(\"\\tF1: %1.3f\" % f1_score(y_test, y_pred_bayes))\n",
    "    print(\"\\tAccuracy: %1.3f\\n\" % accuracy_score(y_test, y_pred_bayes))\n",
    "    \n",
    "    list_pre.append(precision_score(y_test, y_pred_bayes))\n",
    "    list_rec.append(recall_score(y_test, y_pred_bayes))\n",
    "    list_f1.append(f1_score(y_test, y_pred_bayes))\n",
    "\n",
    "print \"Final Results: L2 Logistic Regression\"\n",
    "print(\"\\tPrecision: %1.3f\" % precision_score(y_test_total, y_pred_bayes_total))\n",
    "print(\"\\tRecall: %1.3f\" % recall_score(y_test_total, y_pred_bayes_total))\n",
    "print(\"\\tF1: %1.3f\" % f1_score(y_test_total, y_pred_bayes_total))\n",
    "print(\"\\tAccuracy: %1.3f\\n\" % accuracy_score(y_test_total, y_pred_bayes_total))\n",
    "print(\"Precision\")\n",
    "print np.max(list_pre)\n",
    "print np.min(list_pre)\n",
    "print np.mean(list_pre)\n",
    "print np.median(list_pre)\n",
    "print np.std(list_pre)\n",
    "print(\"Recall\")\n",
    "print np.max(list_rec)\n",
    "print np.min(list_rec)\n",
    "print np.mean(list_rec)\n",
    "print np.median(list_rec)\n",
    "print np.std(list_rec)\n",
    "print(\"F1\")\n",
    "print np.max(list_f1)\n",
    "print np.min(list_f1)\n",
    "print np.mean(list_f1)\n",
    "print np.median(list_f1)\n",
    "print np.std(list_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 whether or not predictions can be made well across the entire length of the lecture videos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Results: GaussianNB\n",
      "\tPrecision: 0.458\n",
      "\tRecall: 0.846\n",
      "\tF1: 0.595\n",
      "\tAccuracy: 0.706\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.metrics import (precision_score, recall_score, f1_score, accuracy_score)\n",
    "## Read data from features_labels_tobii.csv\n",
    "\n",
    "df_merge = pd.read_csv(\"features_labels_webgazer.csv\")\n",
    "list_id_report = list(df_merge['id'].unique())\n",
    "\n",
    "y_test_total = []\n",
    "y_pred_bayes_total = []\n",
    "\n",
    "list_pre = []\n",
    "list_rec = []\n",
    "list_f1 = []\n",
    "\n",
    "## Leave-one-out machine learning methods (try Logistic Regression first)\n",
    "for i in range(0, len(list_id_report)):\n",
    "    id_str = list_id_report[i]    \n",
    "    \n",
    "    # data_train = df_merge.ix[df_merge['id'] != id_str]\n",
    "    # data_train = data_train.ix[data_train['video_id'] == \"Solar\"]\n",
    "    # data_train = data_train.ix[data_train['video_id'] != \"Solar\"]\n",
    "    \n",
    "    # data_train = df_merge\n",
    "    # data_train = data_train.ix[data_train['video_id'] != \"Solar\"]\n",
    "    \n",
    "    data_train = df_merge\n",
    "    data_train = data_train.ix[((data_train['video_id'] == \"Solar\")&\n",
    "                                (data_test['endtime_video']/data_test['video_length'] >= 0.5))|\n",
    "                               (data_train['video_id'] != \"Solar\")\n",
    "                              ]\n",
    "    \n",
    "    # print data_train.shape\n",
    "    data_test = df_merge.ix[df_merge['id'] == id_str]\n",
    "    data_test = data_test.ix[(data_test['video_id'] == \"Solar\")&(data_test['endtime_video']/data_test['video_length'] < 0.5)]\n",
    "    # print data_test.shape\n",
    "    X_train = data_train.ix[:, 10:].fillna(value=0)\n",
    "    y_train = data_train.ix[:, 4]\n",
    "    \n",
    "#     sm = SMOTE(random_state=48)\n",
    "#     X_train, y_train = sm.fit_sample(X_train, y_train)\n",
    "    \n",
    "    X_test = data_test.ix[:, 10:].fillna(value=0)\n",
    "    y_test = data_test.ix[:, 4]\n",
    "    \n",
    "    y_test_total.extend(y_test)\n",
    "    \n",
    "    ## Logistic Regression\n",
    "    \n",
    "    clf_GaussianNB = GaussianNB()\n",
    "    clf_GaussianNB = clf_GaussianNB.fit(X_train, y_train)\n",
    "    y_pred_bayes = clf_GaussianNB.predict(X_test)\n",
    "    y_pred_bayes_total.extend(y_pred_bayes)\n",
    "    \n",
    "    list_pre.append(precision_score(y_test, y_pred_bayes))\n",
    "    list_rec.append(recall_score(y_test, y_pred_bayes))\n",
    "    list_f1.append(f1_score(y_test, y_pred_bayes))\n",
    "\n",
    "print \"Final Results: GaussianNB\"\n",
    "print(\"\\tPrecision: %1.3f\" % precision_score(y_test_total, y_pred_bayes_total))\n",
    "print(\"\\tRecall: %1.3f\" % recall_score(y_test_total, y_pred_bayes_total))\n",
    "print(\"\\tF1: %1.3f\" % f1_score(y_test_total, y_pred_bayes_total))\n",
    "print(\"\\tAccuracy: %1.3f\\n\" % accuracy_score(y_test_total, y_pred_bayes_total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 whether or not a model trained on one video translates to good predictions in other videos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Results: GaussianNB\n",
      "\tPrecision: 0.407\n",
      "\tRecall: 0.815\n",
      "\tF1: 0.543\n",
      "\tAccuracy: 0.593\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.metrics import (precision_score, recall_score, f1_score, accuracy_score)\n",
    "## Read data from features_labels_tobii.csv\n",
    "\n",
    "# df_merge = pd.read_csv(\"features_labels_tobii.csv\")\n",
    "df_merge = pd.read_csv(\"features_labels_webgazer.csv\")\n",
    "list_id_report = list(df_merge['id'].unique())\n",
    "\n",
    "y_test_total = []\n",
    "y_pred_bayes_total = []\n",
    "\n",
    "list_pre = []\n",
    "list_rec = []\n",
    "list_f1 = []\n",
    "\n",
    "## Leave-one-out machine learning methods (try Logistic Regression first)\n",
    "for i in range(0, len(list_id_report)):\n",
    "    id_str = list_id_report[i]    \n",
    "    \n",
    "    data_train = df_merge.ix[df_merge['id'] != id_str]\n",
    "    # data_train = data_train.ix[data_train['video_id'] == \"Solar\"]\n",
    "    data_train = data_train.ix[data_train['video_id'] != \"Solar\"]\n",
    "    \n",
    "    # data_train = df_merge\n",
    "    # data_train = data_train.ix[data_train['video_id'] != \"Solar\"]\n",
    "    \n",
    "    #  data_train = df_merge\n",
    "    #  data_train = data_train.ix[data_train['video_id'] == \"Solar\"]\n",
    "    \n",
    "    # print data_train.shape\n",
    "    data_test = df_merge.ix[df_merge['id'] == id_str]\n",
    "    # data_test = data_test.ix[data_test['video_id'] == \"Solar\"]\n",
    "    data_test = data_test.ix[data_test['video_id'] != \"Solar\"]\n",
    "    \n",
    "    # print data_test.shape\n",
    "    X_train = data_train.ix[:, 10:].fillna(value=0)\n",
    "    y_train = data_train.ix[:, 4]\n",
    "    \n",
    "#     sm = SMOTE(random_state=48)\n",
    "#     X_train, y_train = sm.fit_sample(X_train, y_train)\n",
    "    \n",
    "    X_test = data_test.ix[:, 10:].fillna(value=0)\n",
    "    y_test = data_test.ix[:, 4]\n",
    "    \n",
    "    y_test_total.extend(y_test)\n",
    "    \n",
    "    ## Logistic Regression\n",
    "    \n",
    "    clf_GaussianNB = GaussianNB()\n",
    "    clf_GaussianNB = clf_GaussianNB.fit(X_train, y_train)\n",
    "    y_pred_bayes = clf_GaussianNB.predict(X_test)\n",
    "    y_pred_bayes_total.extend(y_pred_bayes)\n",
    "    \n",
    "    list_pre.append(precision_score(y_test, y_pred_bayes))\n",
    "    list_rec.append(recall_score(y_test, y_pred_bayes))\n",
    "    list_f1.append(f1_score(y_test, y_pred_bayes))\n",
    "\n",
    "print \"Final Results: GaussianNB\"\n",
    "print(\"\\tPrecision: %1.3f\" % precision_score(y_test_total, y_pred_bayes_total))\n",
    "print(\"\\tRecall: %1.3f\" % recall_score(y_test_total, y_pred_bayes_total))\n",
    "print(\"\\tF1: %1.3f\" % f1_score(y_test_total, y_pred_bayes_total))\n",
    "print(\"\\tAccuracy: %1.3f\\n\" % accuracy_score(y_test_total, y_pred_bayes_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
